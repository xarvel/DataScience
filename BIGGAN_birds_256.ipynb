{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mw4l2saP3EF",
        "outputId": "e8b1caaf-2e49-431c-85c6-2c664752f5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BigGANUtils'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 119 (delta 76), reused 68 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 34.93 MiB | 10.34 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gan tensorflow-addons imageio -q\n",
        "!rm -rf sample_data BigGANUtils checkpoints samples\n",
        "!mkdir checkpoints samples\n",
        "!git clone https://github.com/xarvel/BigGANUtils.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "17726c20-ec48-426d-dc34-b0c700c88983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Concatenate, ReLU,  BatchNormalization, Reshape, Embedding\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "import imageio\n",
        "import glob\n",
        "import IPython\n",
        "import math\n",
        "from BigGANUtils.SelfAttention import SelfAttention\n",
        "from BigGANUtils.GBlock import GBlock\n",
        "from BigGANUtils.DBlock import DBlock\n",
        "from BigGANUtils.SpectralNormalization import SpectralNormalization\n",
        "from BigGANUtils.ConditionalBatchNormalization import ConditionalBatchNormalization\n",
        "from BigGANUtils.SNDense import SNDense \n",
        "from BigGANUtils.SNConv2D import SNConv2D\n",
        "from BigGANUtils.SNEmbedding import SNEmbedding\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "b0663eb3-8b48-4842-ebdf-c1fb1c83f3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ],
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "outputs": [],
      "source": [
        "#@title CONFIG\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "IMAGE_CHANNELS = 3\n",
        "DATASET_SIZE = 13262\n",
        "BUFFER_SIZE = DATASET_SIZE\n",
        "PER_REPILICA_BATCH_SIZE = 8\n",
        "GLOBAL_BATCH_SIZE = PER_REPILICA_BATCH_SIZE * strategy.num_replicas_in_sync\n",
        "EPOCHS = 30\n",
        "LATENT_DIM = 126\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "SAMPLES_DIR = 'samples'\n",
        "CHECKPOINT_INTERVAL = 5\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n",
        "SAMPLE_INTERVAL = 1\n",
        "\n",
        "GAN_FILTERS = 64\n",
        "GENERATOR_LR = 0.0001\n",
        "DISCRIMINATOR_LR = 0.0004\n",
        "ADAM_BETA_1 = 0.0\n",
        "ADAM_BETA_2 = 0.99\n",
        "ADAM_EPSILON = 1e-07"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(SEED)\n",
        "\n",
        "weight_initializer = 'orthogonal' \n",
        "\n",
        "# weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "#     mean=0.0, stddev=0.02, seed=SEED\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "outputs": [],
      "source": [
        "#@title Dataset\n",
        "\n",
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "\n",
        "    def augment(image, label):\n",
        "      image = tf.image.random_flip_left_right(\n",
        "          image, seed=SEED\n",
        "      )\n",
        "\n",
        "      return image, label  \n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    \n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True, seed=SEED)\n",
        "      dataset = dataset.repeat()\n",
        "      dataset = dataset.map(augment)\n",
        "\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=GLOBAL_BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "outputs": [],
      "source": [
        "#@title Generator\n",
        "\n",
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SNDense(4 * 4 * 16 * channels, use_bias=False, kernel_initializer=weight_initializer)\n",
        "    self.reshape = Reshape([4, 4, 16 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(16 * channels, kernel_initializer=weight_initializer)\n",
        "    self.res_block_2 = GBlock(8 * channels, kernel_initializer=weight_initializer)\n",
        "    self.res_block_3 = GBlock(8 * channels, kernel_initializer=weight_initializer)\n",
        "    self.res_block_4 = GBlock(4 * channels, kernel_initializer=weight_initializer)\n",
        "    self.res_block_5 = GBlock(2 * channels, kernel_initializer=weight_initializer)\n",
        "    self.attention = SelfAttention(kernel_initializer=weight_initializer)\n",
        "    self.res_block_6 = GBlock(channels, kernel_initializer=weight_initializer)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = ReLU()\n",
        "    self.conv = SNConv2D(filters=IMAGE_CHANNELS, kernel_size=3, padding='same', kernel_initializer=weight_initializer)\n",
        "    self.concat = Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=7, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.res_block_4(x, conds[3], training=training)\n",
        "    x = self.res_block_5(x, conds[4], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_6(x, conds[5], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17n0QCgeWgmr"
      },
      "outputs": [],
      "source": [
        "#@title Discriminator\n",
        "\n",
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(1 * channels, downsample=True, preactivation=False,  kernel_initializer=weight_initializer)\n",
        "    self.res_block_2 = DBlock(2 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.res_block_4 = DBlock(8 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.res_block_5 = DBlock(8 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.res_block_6 = DBlock(16 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.attention = SelfAttention(kernel_initializer=weight_initializer)\n",
        "    self.res_block_7 = DBlock(16 * channels, downsample=False, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.activation = ReLU()\n",
        "    self.embedding = SNEmbedding(num_classes, 16 * channels, embeddings_initializer=weight_initializer)\n",
        "    self.linear = SNDense(1, kernel_initializer=weight_initializer)\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.res_block_5(x, training=training)\n",
        "    x = self.res_block_6(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_7(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DkA2GYMW08M"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(GAN_FILTERS, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  discriminator = Discriminator(GAN_FILTERS, num_classes=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "outputs": [],
      "source": [
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=PER_REPILICA_BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "outputs": [],
      "source": [
        "hinge = tf.keras.losses.Hinge(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "def discriminator_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor :\n",
        "  real_loss = hinge(tf.ones_like(logits_real), logits_real)\n",
        "  fake_loss = hinge(tf.zeros_like(logits_fake), logits_fake)\n",
        "  total_loss = real_loss + fake_loss\n",
        "\n",
        "  return tf.nn.compute_average_loss(total_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "def generator_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  loss = hinge(tf.ones_like(logits_fake), logits_fake)\n",
        "  return tf.nn.compute_average_loss(loss, global_batch_size=GLOBAL_BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = Adam(\n",
        "      learning_rate=GENERATOR_LR, \n",
        "      beta_1=ADAM_BETA_1, \n",
        "      beta_2=ADAM_BETA_2,\n",
        "      epsilon=ADAM_EPSILON\n",
        "  )\n",
        "  discriminator_optimizer = Adam(\n",
        "      learning_rate=DISCRIMINATOR_LR, \n",
        "      beta_1=ADAM_BETA_1, \n",
        "      beta_2=ADAM_BETA_2, \n",
        "      epsilon=ADAM_EPSILON\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "fixed_noise = tf.random.truncated_normal((NUM_CLASSES, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_single_image():\n",
        "  label = tf.constant([random.randint(0, 10)])\n",
        "  noise = tf.random.truncated_normal([1, LATENT_DIM], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  \n",
        "\n",
        "def sample_images(epoch=0, save=False, show=True):\n",
        "  square_size = int(math.sqrt(NUM_CLASSES))\n",
        "  rows = square_size\n",
        "  cols = square_size\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, NUM_CLASSES)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(\n",
        "      wspace = 0.0,\n",
        "      hspace = 0.0\n",
        "  )\n",
        "  px = 1/plt.rcParams['figure.dpi']\n",
        "\n",
        "  fig.set_figheight(IMAGE_SIZE * rows * px)\n",
        "  fig.set_figwidth(IMAGE_SIZE * cols * px)\n",
        "\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * square_size + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "\n",
        "  # Create folder if not exits\n",
        "  if not os.path.isdir(SAMPLES_DIR):\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "\n",
        "  if save:\n",
        "    plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    \n",
        "  if show:\n",
        "    plt.show()\n",
        "  else:\n",
        "    plt.close(fig)\n",
        "\n",
        "def sample_analytics(meta, save=False, show=True):\n",
        "  history = meta['history']\n",
        "\n",
        "  with plt.xkcd():\n",
        "    fig, axs = plt.subplots(figsize=(10,10))\n",
        "    plt.plot(history['gen_loss'], label='Generator loss')\n",
        "    plt.plot(history['disc_loss'], label='Discriminator loss')\n",
        "    plt.title('Learing process')\n",
        "    \n",
        "    plt.figtext(.7, .17, '\\n'.join([\n",
        "        'Epoch=%s' % meta['epoch'],\n",
        "        \"GEN_LR=%s\" % GENERATOR_LR,\n",
        "        'DISC_LR=%s' % DISCRIMINATOR_LR,\n",
        "        'FILTERS=%s' % GAN_FILTERS,\n",
        "        'PER_REPILICA_BATCH_SIZE=%s' % PER_REPILICA_BATCH_SIZE\n",
        "    ]))\n",
        "\n",
        "    fig.legend();\n",
        "\n",
        "    if save:\n",
        "      fig.savefig(SAMPLES_DIR + '/analytics_at_epoch_{:04d}.png'.format(meta['epoch'])) \n",
        "  \n",
        "    if show:   \n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlPAqdghEYZ9"
      },
      "outputs": [],
      "source": [
        "#@title checkpoint\n",
        "import json\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator\n",
        ")\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "\n",
        "defaultMeta = {\n",
        "    \"history\": {\n",
        "        \"disc_loss\": [],\n",
        "        \"gen_loss\": []\n",
        "    },\n",
        "    \"epoch\": 1\n",
        "}\n",
        "meta = defaultMeta\n",
        "\n",
        "META_FILE = CHECKPOINT_DIR + '/meta.json'\n",
        "\n",
        "def restore_checkpoint():\n",
        "  try:\n",
        "    with open(META_FILE) as f:\n",
        "      meta = json.load(f)\n",
        "  except:\n",
        "    meta = defaultMeta\n",
        "    pass\n",
        "  \n",
        "  status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "  return meta\n",
        "\n",
        "def save_checkpoint():\n",
        "  print('Saving checkpoint');\n",
        "\n",
        "  # Create folder if not exits\n",
        "  if not os.path.isdir(SAMPLES_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "  with open(META_FILE, 'w') as f:\n",
        "    json.dump(meta, f)\n",
        "  \n",
        "  checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "\n",
        "meta = restore_checkpoint();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "shjyDN-zLfpG",
        "outputId": "63b5fb4a-b19a-4cd4-f75e-d51550a06ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 256, 256, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, LATENT_DIM], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQyAtYtnLn8B",
        "outputId": "d6a5a241-4f9a-4e79-a5f8-a2a0fe3b2093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.7118281]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PE9md58XNvq"
      },
      "outputs": [],
      "source": [
        "#@title train_step\n",
        "\n",
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([PER_REPILICA_BATCH_SIZE, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    \n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ky4ZH-23EiPG",
        "outputId": "e84d8f43-6733-4cb0-9bc6-fbc58a71ce98"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1657 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall_1:2\", shape=(8,), dtype=int64), values=Tensor(\"PartitionedCall_1:1\", shape=(8, 126), dtype=float32), dense_shape=Tensor(\"PartitionedCall_1:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "Current step 1657: 100%|██████████| 1657/1657 [20:09<00:00,  1.37it/s, disc_loss=0.0197, gen_loss=0.381]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 1233.6989715099335 sec\n",
            "Epoch: 2/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 3314: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0089, gen_loss=0.398]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 2 is 736.5194582939148 sec\n",
            "Epoch: 3/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 4971: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0146, gen_loss=0.56]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 3 is 736.4211058616638 sec\n",
            "Epoch: 4/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 6628: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0438, gen_loss=0.35]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 4 is 736.0320839881897 sec\n",
            "Epoch: 5/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 8285: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0246, gen_loss=0.553]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 5 is 747.9996371269226 sec\n",
            "Epoch: 6/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 9942: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0047, gen_loss=0.423]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 6 is 737.333788394928 sec\n",
            "Epoch: 7/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 11599: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0246, gen_loss=0.361]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 7 is 737.6743831634521 sec\n",
            "Epoch: 8/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 13256: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0054, gen_loss=0.475]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 8 is 736.455418586731 sec\n",
            "Epoch: 9/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 14913: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0077, gen_loss=0.372]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 9 is 736.5922243595123 sec\n",
            "Epoch: 10/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 16570: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0061, gen_loss=0.464]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 10 is 743.7092266082764 sec\n",
            "Epoch: 11/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 18227: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0171, gen_loss=0.554]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 11 is 738.565826177597 sec\n",
            "Epoch: 12/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 19884: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0636, gen_loss=0.281]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 12 is 736.0683350563049 sec\n",
            "Epoch: 13/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 21541: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0111, gen_loss=0.445]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 13 is 735.6449587345123 sec\n",
            "Epoch: 14/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 23198: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0117, gen_loss=0.427]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 14 is 736.3620944023132 sec\n",
            "Epoch: 15/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 24855: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0255, gen_loss=0.363]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 15 is 744.0709972381592 sec\n",
            "Epoch: 16/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 26512: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0258, gen_loss=0.41]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 16 is 737.1061577796936 sec\n",
            "Epoch: 17/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 28169: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0624, gen_loss=0.57]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 17 is 737.5719110965729 sec\n",
            "Epoch: 18/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 29826: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0585, gen_loss=0.499]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 18 is 736.9986388683319 sec\n",
            "Epoch: 19/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 31483: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0275, gen_loss=0.443]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 19 is 740.5999364852905 sec\n",
            "Epoch: 20/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 33140: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.103, gen_loss=0.58]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 20 is 744.2545096874237 sec\n",
            "Epoch: 21/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 34797: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0219, gen_loss=0.438]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 21 is 736.3453915119171 sec\n",
            "Epoch: 22/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current step 36454: 100%|██████████| 1657/1657 [11:56<00:00,  2.31it/s, disc_loss=0.0303, gen_loss=0.425]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time for epoch 22 is 735.888087272644 sec\n",
            "Epoch: 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38111: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0512, gen_loss=0.529]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 23 is 736.1601538658142 sec\n",
            "Epoch: 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 39768: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0456, gen_loss=0.301]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 24 is 736.6365659236908 sec\n",
            "Epoch: 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41425: 100%|██████████| 1657/1657 [11:57<00:00,  2.31it/s, disc_loss=0.0266, gen_loss=0.396]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 25 is 744.6022510528564 sec\n",
            "Epoch: 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41765:  21%|██        | 340/1657 [02:27<09:31,  2.31it/s, disc_loss=0.0304, gen_loss=0.397]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-623a35d96b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disc_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'disc_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gen_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__float__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "steps_per_epoch = DATASET_SIZE // PER_REPILICA_BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(meta['epoch'], EPOCHS + 1):\n",
        "  meta['epoch'] = epoch\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    meta['history']['disc_loss'].append(float(disc_loss));\n",
        "    meta['history']['gen_loss'].append(float(gen_loss));\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "\n",
        "  if epoch % SAMPLE_INTERVAL == 0:\n",
        "    sample_images(epoch, save=True, show=False)\n",
        "    \n",
        "  if epoch % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "    sample_analytics(meta, save=True, show=False)   \n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch, time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JE2jWBg8mtz"
      },
      "outputs": [],
      "source": [
        "sample_analytics(meta, save=False, show=True)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_jHOMjsadKB"
      },
      "outputs": [],
      "source": [
        "sample_images(meta['epoch'], save=False, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjngB_Bgxiq6"
      },
      "outputs": [],
      "source": [
        "samples = SAMPLES_DIR + '/samples.gif'\n",
        "\n",
        "with imageio.get_writer(samples, mode='I') as writer:\n",
        "  filenames = glob.glob(SAMPLES_DIR + '/image_at_epoch_*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWOiE7GgxlDu"
      },
      "outputs": [],
      "source": [
        "IPython.display.Image(filename=samples, embed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XwtZOc6d4kT"
      },
      "outputs": [],
      "source": [
        "sample_single_image()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyML/zyRg/4lHJ/lKPQFonCV",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}