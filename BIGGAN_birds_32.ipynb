{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons imageio -q\n",
        "!rm -rf sample_data BigGANUtils checkpoints samples\n",
        "!mkdir checkpoints samples\n",
        "!git clone https://github.com/xarvel/BigGANUtils.git"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffaa6d3-1b3d-429d-c0d3-d394ca278808"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BigGANUtils'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 119 (delta 76), reused 68 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 34.93 MiB | 10.38 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "dcb6ae61-54d4-4180-9821-e66d335e70db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Concatenate, ReLU,  BatchNormalization, Reshape, Embedding\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "import imageio\n",
        "import glob\n",
        "import IPython\n",
        "import math\n",
        "from BigGANUtils.SelfAttention import SelfAttention\n",
        "from BigGANUtils.GBlock import GBlock\n",
        "from BigGANUtils.DBlock import DBlock\n",
        "from BigGANUtils.SpectralNormalization import SpectralNormalization\n",
        "from BigGANUtils.ConditionalBatchNormalization import ConditionalBatchNormalization\n",
        "from BigGANUtils.SNDense import SNDense \n",
        "from BigGANUtils.SNConv2D import SNConv2D\n",
        "from BigGANUtils.SNEmbedding import SNEmbedding\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "8c0c095b-aabe-40ac-abf2-f78a5d44b6b6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.42.23.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "IMAGE_CHANNELS = 3\n",
        "DATASET_SIZE = 13262\n",
        "BUFFER_SIZE = DATASET_SIZE\n",
        "PER_REPILICA_BATCH_SIZE = 8\n",
        "GLOBAL_BATCH_SIZE = PER_REPILICA_BATCH_SIZE * strategy.num_replicas_in_sync\n",
        "EPOCHS = 25\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "SAMPLES_DIR = 'samples'\n",
        "CHECKPOINT_INTERVAL = 10\n",
        "SEED = 1\n",
        "SAMPLE_INTERVAL = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n",
        "\n",
        "GAN_FILTERS = 64\n",
        "GENERATOR_LR = 0.0001\n",
        "DISCRIMINATOR_LR = 0.0004\n",
        "ADAM_BETA_1 = 0.0\n",
        "ADAM_BETA_2 = 0.99\n",
        "ADAM_EPSILON = 1e-07"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(SEED)\n",
        "\n",
        "weight_initializer = 'orthogonal' \n",
        "\n",
        "# weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "#     mean=0.0, stddev=0.02, seed=SEED\n",
        "# )\n",
        "     "
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset\n",
        "\n",
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "\n",
        "    def augment(image, label):\n",
        "      image = tf.image.random_flip_left_right(\n",
        "          image, seed=SEED\n",
        "      )\n",
        "\n",
        "      return image, label  \n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    \n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True, seed=SEED)\n",
        "      dataset = dataset.repeat()\n",
        "      dataset = dataset.map(augment)\n",
        "\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=GLOBAL_BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SNDense(4 * 4 * 4 * channels, use_bias=False, kernel_initializer=weight_initializer)\n",
        "    self.reshape = Reshape([4, 4, 4 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(4 * channels, kernel_initializer=weight_initializer)\n",
        "    self.res_block_2 = GBlock(4 * channels, kernel_initializer=weight_initializer)\n",
        "    self.attention = SelfAttention(kernel_initializer=weight_initializer)\n",
        "    self.res_block_3 = GBlock(4 * channels, kernel_initializer=weight_initializer)\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = ReLU()\n",
        "    self.conv = SNConv2D(filters=IMAGE_CHANNELS, kernel_size=3, padding='same', kernel_initializer=weight_initializer)\n",
        "    self.concat = Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=4, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(4 * channels, downsample=True, preactivation=False, kernel_initializer=weight_initializer)\n",
        "    self.res_block_2 = DBlock(4 * channels, downsample=True, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=False, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.attention = SelfAttention(kernel_initializer=weight_initializer)\n",
        "    self.res_block_4 = DBlock(4 * channels, downsample=False, preactivation=True, kernel_initializer=weight_initializer)\n",
        "    self.activation = ReLU()\n",
        "    self.embedding = SNEmbedding(num_classes, 4 * channels, embeddings_initializer=weight_initializer)\n",
        "    self.linear = SNDense(1, kernel_initializer=weight_initializer)\n",
        "    \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(GAN_FILTERS, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  discriminator = Discriminator(GAN_FILTERS, num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "4DkA2GYMW08M"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=PER_REPILICA_BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor :\n",
        "  real_loss = tf.reduce_mean(tf.nn.relu(1.0 - logits_real))\n",
        "  fake_loss = tf.reduce_mean(tf.nn.relu(1.0 + logits_fake))\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss / GLOBAL_BATCH_SIZE\n",
        "\n",
        "def generator_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  loss = -tf.reduce_mean(logits_fake)\n",
        "  \n",
        "  return loss / GLOBAL_BATCH_SIZE"
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = Adam(\n",
        "      learning_rate=GENERATOR_LR, \n",
        "      beta_1=ADAM_BETA_1, \n",
        "      beta_2=ADAM_BETA_2,\n",
        "      epsilon=ADAM_EPSILON\n",
        "  )\n",
        "  discriminator_optimizer = Adam(\n",
        "      learning_rate=DISCRIMINATOR_LR, \n",
        "      beta_1=ADAM_BETA_1, \n",
        "      beta_2=ADAM_BETA_2, \n",
        "      epsilon=ADAM_EPSILON\n",
        "  )"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "fixed_noise = tf.random.truncated_normal((NUM_CLASSES, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch=0, save=False, show=True):\n",
        "  square_size = int(math.sqrt(NUM_CLASSES))\n",
        "  rows = square_size\n",
        "  cols = square_size\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, NUM_CLASSES)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(\n",
        "      wspace = 0.0,\n",
        "      hspace = 0.0\n",
        "  )\n",
        "  px = 1/plt.rcParams['figure.dpi']\n",
        "\n",
        "  fig.set_figheight(IMAGE_SIZE * rows * px)\n",
        "  fig.set_figwidth(IMAGE_SIZE * cols * px)\n",
        "\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * square_size + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "\n",
        "  # Create folder if not exits\n",
        "  if not os.path.isdir(SAMPLES_DIR):\n",
        "    os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "\n",
        "  if save:\n",
        "    plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    \n",
        "  if show:\n",
        "    plt.show()\n",
        "  else:\n",
        "    plt.close(fig)\n",
        "\n",
        "def sample_analytics(meta, save=False, show=True):\n",
        "  history = meta['history']\n",
        "\n",
        "  with plt.xkcd():\n",
        "    fig, axs = plt.subplots(figsize=(10,10))\n",
        "    plt.plot(history['gen_loss'], label='Generator loss')\n",
        "    plt.plot(history['disc_loss'], label='Discriminator loss')\n",
        "    plt.title('Learing process')\n",
        "    \n",
        "    plt.figtext(.7, .17, '\\n'.join([\n",
        "        'Epoch=%s' % meta['epoch'],\n",
        "        \"GEN_LR=%s\" % GENERATOR_LR,\n",
        "        'DISC_LR=%s' % DISCRIMINATOR_LR,\n",
        "        'FILTERS=%s' % GAN_FILTERS,\n",
        "        'PER_REPILICA_BATCH_SIZE=%s' % PER_REPILICA_BATCH_SIZE\n",
        "    ]))\n",
        "\n",
        "    fig.legend();\n",
        "\n",
        "    if save:\n",
        "      fig.savefig(SAMPLES_DIR + '/analytics_at_epoch_{:04d}.png'.format(meta['epoch'])) \n",
        "  \n",
        "    if show:   \n",
        "      plt.show()\n",
        "    else:\n",
        "      plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checkpoint\n",
        "import json\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator\n",
        ")\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "\n",
        "defaultMeta = {\n",
        "    \"history\": {\n",
        "        \"disc_loss\": [],\n",
        "        \"gen_loss\": []\n",
        "    },\n",
        "    \"epoch\": 1\n",
        "}\n",
        "meta = defaultMeta\n",
        "\n",
        "META_FILE = CHECKPOINT_DIR + '/meta.json'\n",
        "\n",
        "def restore_checkpoint():\n",
        "  try:\n",
        "    with open(META_FILE) as f:\n",
        "      meta = json.load(f)\n",
        "  except:\n",
        "    meta = defaultMeta\n",
        "    pass\n",
        "  \n",
        "  status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "  return meta\n",
        "\n",
        "def save_checkpoint():\n",
        "  print('Saving checkpoint');\n",
        "\n",
        "  # Create folder if not exits\n",
        "  if not os.path.isdir(SAMPLES_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "  with open(META_FILE, 'w') as f:\n",
        "    json.dump(meta, f)\n",
        "  \n",
        "  checkpoint_prefix = os.path.join(CHECKPOINT_DIR, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "\n",
        "meta = restore_checkpoint();"
      ],
      "metadata": {
        "id": "WLVaiC55QZNx"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, LATENT_DIM], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "8PE9md58XNvq",
        "outputId": "d8f098fc-c185-4e53-b468-f212eedd561a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TUgP7hfQgs6",
        "outputId": "2f920edb-3c15-4dd9-fe5a-d18123c2845f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1.7320564]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train_step\n",
        "\n",
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([PER_REPILICA_BATCH_SIZE, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    \n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss"
      ],
      "metadata": {
        "id": "_SbsFCmyQiyC"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = DATASET_SIZE // PER_REPILICA_BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(meta['epoch'], EPOCHS + 1):\n",
        "  meta['epoch'] = epoch\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    meta['history']['disc_loss'].append(float(disc_loss));\n",
        "    meta['history']['gen_loss'].append(float(gen_loss));\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "\n",
        "  if epoch % SAMPLE_INTERVAL == 0:\n",
        "    sample_images(epoch, save=True, show=False)\n",
        "    \n",
        "  if epoch % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "    sample_analytics(meta, save=True, show=False)   \n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_iORiRgQkiO",
        "outputId": "28aab677-6f7b-4eb0-98bb-64cfa4489330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1657: 100%|██████████| 1657/1657 [04:43<00:00,  5.85it/s, disc_loss=0.0051, gen_loss=0.0255]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 287.54246163368225 sec\n",
            "Epoch: 2/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 3314: 100%|██████████| 1657/1657 [01:04<00:00, 25.55it/s, disc_loss=0.0022, gen_loss=0.0474]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 2 is 66.67989253997803 sec\n",
            "Epoch: 3/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4971: 100%|██████████| 1657/1657 [01:04<00:00, 25.50it/s, disc_loss=0.0041, gen_loss=0.0385]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 3 is 69.33865547180176 sec\n",
            "Epoch: 4/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6628: 100%|██████████| 1657/1657 [01:05<00:00, 25.37it/s, disc_loss=0.0087, gen_loss=0.0563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 4 is 67.0526852607727 sec\n",
            "Epoch: 5/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8285: 100%|██████████| 1657/1657 [01:04<00:00, 25.55it/s, disc_loss=0.0026, gen_loss=0.0405]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 5 is 66.65370488166809 sec\n",
            "Epoch: 6/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 9942: 100%|██████████| 1657/1657 [01:05<00:00, 25.46it/s, disc_loss=0.0045, gen_loss=0.0441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 6 is 66.86038422584534 sec\n",
            "Epoch: 7/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 11599: 100%|██████████| 1657/1657 [01:05<00:00, 25.49it/s, disc_loss=0.0084, gen_loss=0.0545]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 7 is 68.38289213180542 sec\n",
            "Epoch: 8/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 13256: 100%|██████████| 1657/1657 [01:04<00:00, 25.57it/s, disc_loss=0.0067, gen_loss=0.0169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 8 is 66.59944462776184 sec\n",
            "Epoch: 9/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 14913: 100%|██████████| 1657/1657 [01:05<00:00, 25.45it/s, disc_loss=0.0016, gen_loss=0.0316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 9 is 66.84757113456726 sec\n",
            "Epoch: 10/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 16570: 100%|██████████| 1657/1657 [01:04<00:00, 25.52it/s, disc_loss=0.005, gen_loss=0.0282]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint\n",
            "Time for epoch 10 is 69.21889090538025 sec\n",
            "Epoch: 11/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 18227: 100%|██████████| 1657/1657 [01:05<00:00, 25.48it/s, disc_loss=0.0023, gen_loss=0.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 11 is 68.86223006248474 sec\n",
            "Epoch: 12/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19843:  97%|█████████▋| 1614/1657 [01:03<00:01, 25.99it/s, disc_loss=0.0061, gen_loss=0.0556]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_analytics(meta, save=False, show=True)    "
      ],
      "metadata": {
        "id": "roOtopsdQqZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images(meta['epoch'], save=False, show=True)"
      ],
      "metadata": {
        "id": "3BbA3V0_QsBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = SAMPLES_DIR + '/samples.gif'\n",
        "\n",
        "with imageio.get_writer(samples, mode='I') as writer:\n",
        "  filenames = glob.glob(SAMPLES_DIR + '/image_at_epoch_*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "metadata": {
        "id": "Klgcq7QGQtag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Image(filename=samples, embed=True)"
      ],
      "metadata": {
        "id": "1NYoEKIYQvHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}