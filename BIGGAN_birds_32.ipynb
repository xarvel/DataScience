{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIGGAN_birds_32.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAowNBIRDphBiGuHVvDOo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons -q"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "ef881d2f-e10b-43d7-a665-08d5b4c1f837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Embedding\n",
        "from tensorflow.keras.layers import Wrapper, AveragePooling2D, LeakyReLU, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "from tqdm import tqdm \n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow_addons.layers import SpectralNormalization //not working\n",
        "\n",
        "from google.colab import drive, auth\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sJ3KZ6GQ4GX",
        "outputId": "7fd781a8-964d-44a0-db4e-76c5b0fe8abf"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "ccc5b220-b135-45c9-8114-cbafb2a07c5a"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.42.38.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.42.38.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.38.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.42.38.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "BUFFER_SIZE = 13000\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BIGGAN_birds_32/checkpoints'\n",
        "SAMPLES_DIR = '/content/drive/MyDrive/BIGGAN_birds_32/samples'\n",
        "CHECKPOINT_INTERVAL = 50\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "    mean=0.0, stddev=0.02, seed=SEED\n",
        ")\n",
        "weight_regularizer = None\n",
        "weight_regularizer_fully = None"
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralNormalization(Wrapper):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "       layer: tensorflow keras layers (with kernel attribute)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build `Layer`\"\"\"\n",
        "\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "\n",
        "            if not hasattr(self.layer, 'kernel'):\n",
        "                raise ValueError(\n",
        "                    '`SpectralNormalization` must wrap a layer that'\n",
        "                    ' contains a `kernel` for weights')\n",
        "\n",
        "            self.w = self.layer.kernel\n",
        "            self.w_shape = self.w.shape.as_list()\n",
        "            self.u = self.add_weight(\n",
        "                shape=tuple([1, self.w_shape[-1]]),\n",
        "                initializer=k.initializers.TruncatedNormal(stddev=0.02),\n",
        "                name='sn_u',\n",
        "                trainable=False,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        super(SpectralNormalization, self).build()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call `Layer`\"\"\"\n",
        "        # Recompute weights for each forward pass\n",
        "        self._compute_weights()\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        \"\"\"Generate normalized weights.\n",
        "        This method will update the value of self.layer.kernel with the\n",
        "        normalized value, so that the layer is ready for call().\n",
        "        \"\"\"\n",
        "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
        "        eps = 1e-12\n",
        "        _u = tf.identity(self.u)\n",
        "        \n",
        "        _v = tf.matmul(_u, tf.transpose(w_reshaped))\n",
        "        _v = _v / tf.maximum(tf.reduce_sum(_v**2)**0.5, eps)\n",
        "        _u = tf.matmul(_v, w_reshaped)\n",
        "        _u = _u / tf.maximum(tf.reduce_sum(_u**2)**0.5, eps)\n",
        "\n",
        "        self.u.assign(_u)\n",
        "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u))\n",
        "\n",
        "        self.layer.kernel = self.w / sigma\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape(\n",
        "            self.layer.compute_output_shape(input_shape).as_list())"
      ],
      "metadata": {
        "id": "dMyNZbcj_dsD"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConditionalBatchNormalization\n",
        "\n",
        "class ConditionalBatchNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(ConditionalBatchNormalization, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "   \n",
        "    self.linear_gamma = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_gamma'))\n",
        "    self.linear_beta = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_beta'))\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, x, c, training=False):\n",
        "    x = self.batchnorm(x, training=training)\n",
        "    gamma = self.linear_gamma(c, training=training)  \n",
        "    beta = self.linear_beta(c, training=training)\n",
        "\n",
        "    return x * gamma[:, None, None] + beta[:, None, None]  "
      ],
      "metadata": {
        "id": "d4RfhN_MT1Qv"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = int(input_shape[-1])\n",
        "\n",
        "        self.conv_theta =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_phi =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_g =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//2, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_attn =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.sigma = self.add_weight('sigma', shape=[], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        batch_size, h, w, in_channels = map(int, x.shape.as_list())\n",
        "        location_num = h*w\n",
        "        downsampled_num = location_num//4\n",
        "\n",
        "        theta = self.conv_theta(x, training=training)\n",
        "        theta = tf.reshape(theta, [batch_size, location_num, in_channels//8])\n",
        "\n",
        "        phi = self.conv_phi(x, training=training)\n",
        "        phi = tf.nn.max_pool(phi, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        phi = tf.reshape(phi, [batch_size, downsampled_num, in_channels//8])\n",
        "\n",
        "        attn = tf.matmul(theta, phi, transpose_b=True)\n",
        "        attn = tf.nn.softmax(attn)\n",
        "\n",
        "        g = self.conv_g(x, training=training)\n",
        "        g = tf.nn.max_pool(g, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        g = tf.reshape(g, [batch_size, downsampled_num, in_channels//2])\n",
        "\n",
        "        attn_g = tf.matmul(attn, g)\n",
        "        attn_g = tf.reshape(attn_g, [batch_size, h, w, in_channels//2])\n",
        "        attn_g = self.conv_attn(attn_g, training=training)\n",
        "\n",
        "        return x + self.sigma * attn_g"
      ],
      "metadata": {
        "id": "MdSa_hc6UCm5"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DBlock\n",
        "\n",
        "class DBlock(Model):\n",
        "  def __init__(self, channels, downsample=True, preactivation=True):\n",
        "    super(DBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.hidden_channels = self.out_channels \n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.hidden_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.av_pool_1 = AveragePooling2D(padding='same')\n",
        "    self.av_pool_2 = AveragePooling2D(padding='same')\n",
        "    \n",
        "    self.downsample = downsample\n",
        "    self.preactivation = preactivation\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = True if (self.in_channels != self.out_channels) or self.downsample else False\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = tfa.layers.SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "\n",
        "  def shortcut(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "    else:\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      h = self.activation1(x)\n",
        "    else:\n",
        "      h = x    \n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.conv33_2(self.activation2(h), training=training)\n",
        "\n",
        "    if self.downsample:\n",
        "      h = self.av_pool_2(h)     \n",
        "        \n",
        "    return h + self.shortcut(x, training=training)           \n"
      ],
      "metadata": {
        "id": "qPc_lNVnTezv"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GBlock\n",
        "\n",
        "class GBlock(Model):\n",
        "  def __init__(self, channels):\n",
        "    super(GBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.bn1 = ConditionalBatchNormalization()\n",
        "    self.bn2 = ConditionalBatchNormalization()\n",
        "    self.up_sample_1 = UpSampling2D()\n",
        "    self.up_sample_2 = UpSampling2D()\n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.upsample = True\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = self.in_channels != self.out_channels\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "      \n",
        "  def call(self, x, label, training=False):\n",
        "    h = self.activation1(self.bn1(x, label, training=training))\n",
        "    if self.upsample:\n",
        "      h = self.up_sample_1(h)\n",
        "      x = self.up_sample_2(x)\n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.activation2(self.bn2(h, label, training=training))\n",
        "    h = self.conv33_2(h, training=training)\n",
        "\n",
        "    if self.learnable_sc:       \n",
        "      x = self.conv_sc(x, training=training)\n",
        "\n",
        "    return h + x"
      ],
      "metadata": {
        "id": "-Xi8EUT4TVtc"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SpectralNormalization(Dense(4 * 4 * 4 * channels, use_bias=False, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully))\n",
        "    self.reshape = Reshape([4, 4, 4 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(4 * channels)\n",
        "    self.res_block_2 = GBlock(4 * channels)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_3 = GBlock(4 * channels)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.conv = SpectralNormalization(Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.concat = tf.keras.layers.Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=4, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    print(conds[0].shape, conds[0].dtype)\n",
        "\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(64, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, 120], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "VPNrm_yZUIEW",
        "outputId": "21121229-5f49-4d26-8db7-4d52cc55c58c"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 150) <dtype: 'float32'>\n",
            "(1, 150) <dtype: 'float32'>\n",
            "(1, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(4 * channels, downsample=True, preactivation=False)\n",
        "    self.res_block_2 = DBlock(4 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=False, preactivation=True)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_4 = DBlock(4 * channels, downsample=False, preactivation=True)\n",
        "  \n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.embedding = Embedding(num_classes, 4 * channels, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.linear = SpectralNormalization(\n",
        "       Dense(1, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully)\n",
        "    )\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = Discriminator(64, num_classes=NUM_CLASSES)\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkA2GYMW08M",
        "outputId": "583a8c80-391a-4949-ebc2-575320b2106a"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.5194786]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per_replica_batch_size = BATCH_SIZE // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=per_replica_batch_size,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_hinge_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  L_D = -tf.reduce_mean(tf.minimum(0., -1.0 + logits_real)) - tf.reduce_mean(tf.minimum(0., -1.0 - logits_fake))\n",
        "\n",
        "  return L_D    \n",
        "\n",
        "def generator_hinge_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "    L_G = -tf.reduce_mean(logits_fake)\n",
        "    return L_G  "
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.0, beta_2=0.999,epsilon=1e-6,)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0.0, beta_2=0.999, epsilon=1e-6)"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = tf.random.truncated_normal((100, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch):\n",
        "  rows = 10\n",
        "  cols = 10\n",
        "\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, 100)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(wspace=0.01, hspace=0)\n",
        "\n",
        "  fig.set_figheight(100)\n",
        "  fig.set_figwidth(100)\n",
        "  fig.set_tight_layout(True)\n",
        " \n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * 10 + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "  plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([per_replica_batch_size, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_hinge_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_hinge_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        " \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "  discriminator_optimizer=discriminator_optimizer,\n",
        "  generator=generator,\n",
        "  discriminator=discriminator)\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "\n",
        "if latest_checkpoint:\n",
        "  first_epoch = int(latest_checkpoint.split(sep='ckpt-')[-1]) * CHECKPOINT_INTERVAL\n",
        "else:\n",
        "  first_epoch = 0\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "def save_checkpoint():\n",
        "  checkpoint_dir = CHECKPOINT_DIR\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "\n",
        "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(first_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch + 1, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    sample_images(epoch)\n",
        "  if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PE9md58XNvq",
        "outputId": "d18e0425-fe7c-43c2-cbb5-450d740f9119"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/406 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 150) <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall_1:2\", shape=(4,), dtype=int64), values=Tensor(\"PartitionedCall_1:1\", shape=(4, 120), dtype=float32), dense_shape=Tensor(\"PartitionedCall_1:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_1:0\", shape=(8,), dtype=int64), values=Tensor(\"concat:0\", shape=(8, 256), dtype=float32), dense_shape=Tensor(\"PartitionedCall_2:47\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 150) <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 406: 100%|██████████| 406/406 [03:35<00:00,  1.88it/s, disc_loss=0.103, gen_loss=1.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 215.73420906066895 sec\n",
            "Epoch: 2/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 812: 100%|██████████| 406/406 [00:12<00:00, 32.78it/s, disc_loss=0.0417, gen_loss=1.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 2 is 12.390456199645996 sec\n",
            "Epoch: 3/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1218: 100%|██████████| 406/406 [00:12<00:00, 32.94it/s, disc_loss=0.643, gen_loss=0.585]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 3 is 12.329619407653809 sec\n",
            "Epoch: 4/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1624: 100%|██████████| 406/406 [00:12<00:00, 32.67it/s, disc_loss=0.661, gen_loss=1.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 4 is 12.433025360107422 sec\n",
            "Epoch: 5/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2030: 100%|██████████| 406/406 [00:12<00:00, 32.76it/s, disc_loss=0.184, gen_loss=2.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 150) <dtype: 'float32'>\n",
            "Time for epoch 5 is 27.58542513847351 sec\n",
            "Epoch: 6/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2436: 100%|██████████| 406/406 [00:12<00:00, 33.01it/s, disc_loss=0.229, gen_loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 6 is 12.306437492370605 sec\n",
            "Epoch: 7/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2842: 100%|██████████| 406/406 [00:12<00:00, 32.89it/s, disc_loss=0.677, gen_loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 7 is 12.351293802261353 sec\n",
            "Epoch: 8/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 3248: 100%|██████████| 406/406 [00:12<00:00, 32.91it/s, disc_loss=0.0925, gen_loss=3.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 8 is 12.342841386795044 sec\n",
            "Epoch: 9/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 3654: 100%|██████████| 406/406 [00:12<00:00, 32.90it/s, disc_loss=0.354, gen_loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 9 is 12.34571123123169 sec\n",
            "Epoch: 10/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4060: 100%|██████████| 406/406 [00:12<00:00, 32.68it/s, disc_loss=0.415, gen_loss=2.96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 10 is 25.08110809326172 sec\n",
            "Epoch: 11/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4466: 100%|██████████| 406/406 [00:12<00:00, 32.59it/s, disc_loss=0.201, gen_loss=3.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 11 is 12.460964679718018 sec\n",
            "Epoch: 12/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4872: 100%|██████████| 406/406 [00:12<00:00, 32.66it/s, disc_loss=0.456, gen_loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 12 is 12.43446660041809 sec\n",
            "Epoch: 13/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 5278: 100%|██████████| 406/406 [00:12<00:00, 32.68it/s, disc_loss=0.526, gen_loss=3.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 13 is 12.428581237792969 sec\n",
            "Epoch: 14/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 5684: 100%|██████████| 406/406 [00:12<00:00, 32.23it/s, disc_loss=0.287, gen_loss=1.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 14 is 12.605518102645874 sec\n",
            "Epoch: 15/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6090: 100%|██████████| 406/406 [00:12<00:00, 32.37it/s, disc_loss=0.153, gen_loss=2.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 15 is 27.965872287750244 sec\n",
            "Epoch: 16/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6496: 100%|██████████| 406/406 [00:12<00:00, 32.55it/s, disc_loss=0.335, gen_loss=2.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 16 is 12.4788498878479 sec\n",
            "Epoch: 17/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6902: 100%|██████████| 406/406 [00:12<00:00, 32.30it/s, disc_loss=0.3, gen_loss=1.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 17 is 12.575333833694458 sec\n",
            "Epoch: 18/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 7308: 100%|██████████| 406/406 [00:12<00:00, 32.05it/s, disc_loss=0.395, gen_loss=2.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 18 is 12.675200700759888 sec\n",
            "Epoch: 19/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 7714: 100%|██████████| 406/406 [00:12<00:00, 32.35it/s, disc_loss=0.0754, gen_loss=2.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 19 is 12.555582284927368 sec\n",
            "Epoch: 20/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8120: 100%|██████████| 406/406 [00:12<00:00, 32.42it/s, disc_loss=0.149, gen_loss=2.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 20 is 25.32905650138855 sec\n",
            "Epoch: 21/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8526: 100%|██████████| 406/406 [00:12<00:00, 32.57it/s, disc_loss=0.204, gen_loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 21 is 12.471270561218262 sec\n",
            "Epoch: 22/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8932: 100%|██████████| 406/406 [00:12<00:00, 32.44it/s, disc_loss=0.118, gen_loss=3.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 22 is 12.52028203010559 sec\n",
            "Epoch: 23/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 9338: 100%|██████████| 406/406 [00:12<00:00, 32.89it/s, disc_loss=0.0923, gen_loss=2.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 23 is 12.351402282714844 sec\n",
            "Epoch: 24/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 9744: 100%|██████████| 406/406 [00:12<00:00, 32.70it/s, disc_loss=0.259, gen_loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 24 is 12.420223236083984 sec\n",
            "Epoch: 25/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10150: 100%|██████████| 406/406 [00:12<00:00, 32.60it/s, disc_loss=0.255, gen_loss=3.06]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 25 is 25.06396174430847 sec\n",
            "Epoch: 26/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10556: 100%|██████████| 406/406 [00:12<00:00, 32.52it/s, disc_loss=0.436, gen_loss=3.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 26 is 12.490544319152832 sec\n",
            "Epoch: 27/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10962: 100%|██████████| 406/406 [00:12<00:00, 32.72it/s, disc_loss=0.123, gen_loss=2.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 27 is 12.413377523422241 sec\n",
            "Epoch: 28/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 11368: 100%|██████████| 406/406 [00:12<00:00, 32.74it/s, disc_loss=0.873, gen_loss=0.634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 28 is 12.406713247299194 sec\n",
            "Epoch: 29/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 11774: 100%|██████████| 406/406 [00:12<00:00, 32.49it/s, disc_loss=0.516, gen_loss=3.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 29 is 12.501902103424072 sec\n",
            "Epoch: 30/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12180: 100%|██████████| 406/406 [00:12<00:00, 32.41it/s, disc_loss=0.182, gen_loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 30 is 25.191020965576172 sec\n",
            "Epoch: 31/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12586: 100%|██████████| 406/406 [00:12<00:00, 32.35it/s, disc_loss=0.642, gen_loss=0.936]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 31 is 12.556044340133667 sec\n",
            "Epoch: 32/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12992: 100%|██████████| 406/406 [00:12<00:00, 32.32it/s, disc_loss=0.117, gen_loss=1.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 32 is 12.56775689125061 sec\n",
            "Epoch: 33/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 13398: 100%|██████████| 406/406 [00:12<00:00, 32.38it/s, disc_loss=0.203, gen_loss=2.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 33 is 12.544439315795898 sec\n",
            "Epoch: 34/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 13804: 100%|██████████| 406/406 [00:12<00:00, 32.66it/s, disc_loss=0.064, gen_loss=2.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 34 is 12.43693470954895 sec\n",
            "Epoch: 35/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 14210: 100%|██████████| 406/406 [00:12<00:00, 32.35it/s, disc_loss=0.178, gen_loss=2.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 35 is 26.734760522842407 sec\n",
            "Epoch: 36/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 14616: 100%|██████████| 406/406 [00:12<00:00, 32.61it/s, disc_loss=0.536, gen_loss=1.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 36 is 12.456149578094482 sec\n",
            "Epoch: 37/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15022: 100%|██████████| 406/406 [00:12<00:00, 32.69it/s, disc_loss=0.162, gen_loss=2.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 37 is 12.423956155776978 sec\n",
            "Epoch: 38/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15428: 100%|██████████| 406/406 [00:12<00:00, 32.77it/s, disc_loss=0.198, gen_loss=3.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 38 is 12.39283275604248 sec\n",
            "Epoch: 39/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15834: 100%|██████████| 406/406 [00:12<00:00, 32.54it/s, disc_loss=0.209, gen_loss=3.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 39 is 12.482846021652222 sec\n",
            "Epoch: 40/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 16240: 100%|██████████| 406/406 [00:12<00:00, 32.32it/s, disc_loss=0.105, gen_loss=2.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 40 is 25.392264127731323 sec\n",
            "Epoch: 41/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 16646: 100%|██████████| 406/406 [00:12<00:00, 32.53it/s, disc_loss=0.308, gen_loss=3.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 41 is 12.487941026687622 sec\n",
            "Epoch: 42/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17052: 100%|██████████| 406/406 [00:12<00:00, 32.75it/s, disc_loss=0.289, gen_loss=3.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 42 is 12.402074337005615 sec\n",
            "Epoch: 43/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17458: 100%|██████████| 406/406 [00:12<00:00, 32.72it/s, disc_loss=0.233, gen_loss=3.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 43 is 12.413571119308472 sec\n",
            "Epoch: 44/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17864: 100%|██████████| 406/406 [00:12<00:00, 32.34it/s, disc_loss=0.378, gen_loss=3.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 44 is 12.557725667953491 sec\n",
            "Epoch: 45/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 18270: 100%|██████████| 406/406 [00:12<00:00, 32.60it/s, disc_loss=0.0742, gen_loss=2.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 45 is 25.145008325576782 sec\n",
            "Epoch: 46/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 18676: 100%|██████████| 406/406 [00:12<00:00, 32.56it/s, disc_loss=0.158, gen_loss=3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 46 is 12.47445797920227 sec\n",
            "Epoch: 47/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19082: 100%|██████████| 406/406 [00:12<00:00, 32.63it/s, disc_loss=0.187, gen_loss=3.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 47 is 12.445905685424805 sec\n",
            "Epoch: 48/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19488: 100%|██████████| 406/406 [00:12<00:00, 32.22it/s, disc_loss=0.183, gen_loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 48 is 12.608185529708862 sec\n",
            "Epoch: 49/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19894: 100%|██████████| 406/406 [00:12<00:00, 32.53it/s, disc_loss=0.0249, gen_loss=2.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 49 is 12.486960887908936 sec\n",
            "Epoch: 50/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 20300: 100%|██████████| 406/406 [00:12<00:00, 32.73it/s, disc_loss=0.123, gen_loss=3.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 50 is 27.377368211746216 sec\n",
            "Epoch: 51/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 20706: 100%|██████████| 406/406 [00:12<00:00, 32.16it/s, disc_loss=0.188, gen_loss=2.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 51 is 12.626962661743164 sec\n",
            "Epoch: 52/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21112: 100%|██████████| 406/406 [00:12<00:00, 32.53it/s, disc_loss=0.828, gen_loss=4.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 52 is 12.487203598022461 sec\n",
            "Epoch: 53/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21518: 100%|██████████| 406/406 [00:12<00:00, 32.53it/s, disc_loss=0.125, gen_loss=2.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 53 is 12.485059022903442 sec\n",
            "Epoch: 54/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21924: 100%|██████████| 406/406 [00:12<00:00, 32.50it/s, disc_loss=0.168, gen_loss=3.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 54 is 12.498062133789062 sec\n",
            "Epoch: 55/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 22330: 100%|██████████| 406/406 [00:12<00:00, 32.78it/s, disc_loss=0.0935, gen_loss=3.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 55 is 27.009473085403442 sec\n",
            "Epoch: 56/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 22736: 100%|██████████| 406/406 [00:12<00:00, 32.75it/s, disc_loss=0.307, gen_loss=3.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 56 is 12.403661727905273 sec\n",
            "Epoch: 57/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23142: 100%|██████████| 406/406 [00:12<00:00, 32.85it/s, disc_loss=0.0646, gen_loss=3.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 57 is 12.362149715423584 sec\n",
            "Epoch: 58/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23548: 100%|██████████| 406/406 [00:12<00:00, 32.67it/s, disc_loss=0.263, gen_loss=3.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 58 is 12.438515901565552 sec\n",
            "Epoch: 59/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23954: 100%|██████████| 406/406 [00:12<00:00, 32.67it/s, disc_loss=0.443, gen_loss=2.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 59 is 12.432683229446411 sec\n",
            "Epoch: 60/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 24360: 100%|██████████| 406/406 [00:12<00:00, 32.07it/s, disc_loss=0.0389, gen_loss=2.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 60 is 25.323733806610107 sec\n",
            "Epoch: 61/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 24766: 100%|██████████| 406/406 [00:12<00:00, 32.65it/s, disc_loss=0.139, gen_loss=2.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 61 is 12.440523862838745 sec\n",
            "Epoch: 62/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25172: 100%|██████████| 406/406 [00:12<00:00, 32.24it/s, disc_loss=0.405, gen_loss=4.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 62 is 12.599148035049438 sec\n",
            "Epoch: 63/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25578: 100%|██████████| 406/406 [00:12<00:00, 32.64it/s, disc_loss=0.383, gen_loss=3.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 63 is 12.443052291870117 sec\n",
            "Epoch: 64/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25984: 100%|██████████| 406/406 [00:12<00:00, 32.47it/s, disc_loss=0.15, gen_loss=3.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 64 is 12.508507490158081 sec\n",
            "Epoch: 65/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 26390: 100%|██████████| 406/406 [00:12<00:00, 32.86it/s, disc_loss=0.252, gen_loss=2.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 65 is 24.88361930847168 sec\n",
            "Epoch: 66/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 26796: 100%|██████████| 406/406 [00:12<00:00, 32.51it/s, disc_loss=0.288, gen_loss=3.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 66 is 12.491678714752197 sec\n",
            "Epoch: 67/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 27202: 100%|██████████| 406/406 [00:12<00:00, 32.63it/s, disc_loss=0.137, gen_loss=3.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 67 is 12.444948673248291 sec\n",
            "Epoch: 68/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 27608: 100%|██████████| 406/406 [00:12<00:00, 32.59it/s, disc_loss=0.0925, gen_loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 68 is 12.46208119392395 sec\n",
            "Epoch: 69/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28014: 100%|██████████| 406/406 [00:12<00:00, 32.45it/s, disc_loss=0.243, gen_loss=2.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 69 is 12.51618504524231 sec\n",
            "Epoch: 70/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28420: 100%|██████████| 406/406 [00:12<00:00, 32.66it/s, disc_loss=0.0354, gen_loss=3.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 70 is 24.919217824935913 sec\n",
            "Epoch: 71/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28826: 100%|██████████| 406/406 [00:12<00:00, 33.05it/s, disc_loss=0.131, gen_loss=2.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 71 is 12.289007902145386 sec\n",
            "Epoch: 72/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 29232: 100%|██████████| 406/406 [00:12<00:00, 32.80it/s, disc_loss=0.0567, gen_loss=2.87]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 72 is 12.384729862213135 sec\n",
            "Epoch: 73/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 29638: 100%|██████████| 406/406 [00:12<00:00, 32.42it/s, disc_loss=0.169, gen_loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 73 is 12.528477668762207 sec\n",
            "Epoch: 74/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30044: 100%|██████████| 406/406 [00:12<00:00, 32.71it/s, disc_loss=0.393, gen_loss=1.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 74 is 12.41921615600586 sec\n",
            "Epoch: 75/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30450: 100%|██████████| 406/406 [00:12<00:00, 32.79it/s, disc_loss=0.151, gen_loss=3.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 75 is 24.89491891860962 sec\n",
            "Epoch: 76/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30856: 100%|██████████| 406/406 [00:12<00:00, 33.02it/s, disc_loss=0.274, gen_loss=2.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 76 is 12.299102783203125 sec\n",
            "Epoch: 77/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 31262: 100%|██████████| 406/406 [00:12<00:00, 32.80it/s, disc_loss=0.233, gen_loss=3.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 77 is 12.38124966621399 sec\n",
            "Epoch: 78/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 31668: 100%|██████████| 406/406 [00:12<00:00, 32.30it/s, disc_loss=0.169, gen_loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 78 is 12.573124647140503 sec\n",
            "Epoch: 79/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32074: 100%|██████████| 406/406 [00:12<00:00, 32.35it/s, disc_loss=0.0533, gen_loss=2.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 79 is 12.552988052368164 sec\n",
            "Epoch: 80/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32480: 100%|██████████| 406/406 [00:12<00:00, 31.84it/s, disc_loss=0.229, gen_loss=1.91]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 80 is 25.509514093399048 sec\n",
            "Epoch: 81/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32886: 100%|██████████| 406/406 [00:12<00:00, 32.29it/s, disc_loss=0.833, gen_loss=0.756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 81 is 12.578863620758057 sec\n",
            "Epoch: 82/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 33292: 100%|██████████| 406/406 [00:12<00:00, 32.74it/s, disc_loss=0.0755, gen_loss=3.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 82 is 12.406822919845581 sec\n",
            "Epoch: 83/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 33698: 100%|██████████| 406/406 [00:12<00:00, 32.61it/s, disc_loss=0.379, gen_loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 83 is 12.453966617584229 sec\n",
            "Epoch: 84/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34104: 100%|██████████| 406/406 [00:12<00:00, 32.85it/s, disc_loss=0.0395, gen_loss=3.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 84 is 12.365189790725708 sec\n",
            "Epoch: 85/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34510: 100%|██████████| 406/406 [00:12<00:00, 32.91it/s, disc_loss=0.199, gen_loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 85 is 27.5884370803833 sec\n",
            "Epoch: 86/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34916: 100%|██████████| 406/406 [00:12<00:00, 32.60it/s, disc_loss=0.13, gen_loss=3.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 86 is 12.46045708656311 sec\n",
            "Epoch: 87/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 35322: 100%|██████████| 406/406 [00:12<00:00, 33.04it/s, disc_loss=0.177, gen_loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 87 is 12.294127225875854 sec\n",
            "Epoch: 88/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 35728: 100%|██████████| 406/406 [00:12<00:00, 32.98it/s, disc_loss=0.217, gen_loss=1.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 88 is 12.315672159194946 sec\n",
            "Epoch: 89/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36134: 100%|██████████| 406/406 [00:12<00:00, 32.87it/s, disc_loss=0.067, gen_loss=2.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 89 is 12.357136964797974 sec\n",
            "Epoch: 90/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36540: 100%|██████████| 406/406 [00:12<00:00, 32.69it/s, disc_loss=0.175, gen_loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 90 is 25.009658575057983 sec\n",
            "Epoch: 91/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36946: 100%|██████████| 406/406 [00:12<00:00, 32.64it/s, disc_loss=0.161, gen_loss=2.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 91 is 12.443530797958374 sec\n",
            "Epoch: 92/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 37352: 100%|██████████| 406/406 [00:12<00:00, 32.77it/s, disc_loss=0.0806, gen_loss=2.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 92 is 12.39181137084961 sec\n",
            "Epoch: 93/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 37758: 100%|██████████| 406/406 [00:12<00:00, 32.42it/s, disc_loss=0.126, gen_loss=2.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 93 is 12.529048919677734 sec\n",
            "Epoch: 94/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38164: 100%|██████████| 406/406 [00:12<00:00, 32.42it/s, disc_loss=0.123, gen_loss=3.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 94 is 12.529046535491943 sec\n",
            "Epoch: 95/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38570: 100%|██████████| 406/406 [00:12<00:00, 32.72it/s, disc_loss=0.0422, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 95 is 25.200589895248413 sec\n",
            "Epoch: 96/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38976: 100%|██████████| 406/406 [00:12<00:00, 32.59it/s, disc_loss=0.0804, gen_loss=2.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 96 is 12.461555004119873 sec\n",
            "Epoch: 97/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 39382: 100%|██████████| 406/406 [00:12<00:00, 32.76it/s, disc_loss=0.249, gen_loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 97 is 12.397551536560059 sec\n",
            "Epoch: 98/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 39788: 100%|██████████| 406/406 [00:12<00:00, 32.78it/s, disc_loss=0.0532, gen_loss=2.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 98 is 12.390194654464722 sec\n",
            "Epoch: 99/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 40194: 100%|██████████| 406/406 [00:12<00:00, 32.91it/s, disc_loss=0.0906, gen_loss=2.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 99 is 12.34075140953064 sec\n",
            "Epoch: 100/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 40600: 100%|██████████| 406/406 [00:12<00:00, 32.61it/s, disc_loss=0.0857, gen_loss=2.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 100 is 26.967323303222656 sec\n",
            "Epoch: 101/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41006: 100%|██████████| 406/406 [00:12<00:00, 32.30it/s, disc_loss=0.0766, gen_loss=2.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 101 is 12.573922395706177 sec\n",
            "Epoch: 102/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41412: 100%|██████████| 406/406 [00:12<00:00, 33.03it/s, disc_loss=0.0895, gen_loss=2.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 102 is 12.29773211479187 sec\n",
            "Epoch: 103/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41818: 100%|██████████| 406/406 [00:12<00:00, 32.67it/s, disc_loss=0.166, gen_loss=3.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 103 is 12.433046817779541 sec\n",
            "Epoch: 104/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 42224: 100%|██████████| 406/406 [00:12<00:00, 32.84it/s, disc_loss=0.27, gen_loss=2.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 104 is 12.366892576217651 sec\n",
            "Epoch: 105/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 42630: 100%|██████████| 406/406 [00:12<00:00, 32.91it/s, disc_loss=0.0783, gen_loss=2.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 105 is 24.68665051460266 sec\n",
            "Epoch: 106/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43036: 100%|██████████| 406/406 [00:12<00:00, 32.81it/s, disc_loss=0.193, gen_loss=2.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 106 is 12.38198184967041 sec\n",
            "Epoch: 107/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43442: 100%|██████████| 406/406 [00:12<00:00, 32.94it/s, disc_loss=0.0848, gen_loss=3.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 107 is 12.329090595245361 sec\n",
            "Epoch: 108/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43848: 100%|██████████| 406/406 [00:12<00:00, 33.00it/s, disc_loss=0.131, gen_loss=3.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 108 is 12.30971884727478 sec\n",
            "Epoch: 109/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 44254: 100%|██████████| 406/406 [00:12<00:00, 33.02it/s, disc_loss=0.127, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 109 is 12.299233436584473 sec\n",
            "Epoch: 110/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 44660: 100%|██████████| 406/406 [00:12<00:00, 33.04it/s, disc_loss=0.0757, gen_loss=2.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 110 is 24.58611822128296 sec\n",
            "Epoch: 111/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45066: 100%|██████████| 406/406 [00:12<00:00, 32.96it/s, disc_loss=0.178, gen_loss=3.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 111 is 12.323207378387451 sec\n",
            "Epoch: 112/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45472: 100%|██████████| 406/406 [00:12<00:00, 32.94it/s, disc_loss=0.547, gen_loss=0.911]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 112 is 12.328766584396362 sec\n",
            "Epoch: 113/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45878: 100%|██████████| 406/406 [00:12<00:00, 33.07it/s, disc_loss=0.185, gen_loss=2.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 113 is 12.2821626663208 sec\n",
            "Epoch: 114/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 46284: 100%|██████████| 406/406 [00:12<00:00, 33.08it/s, disc_loss=0.0707, gen_loss=2.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 114 is 12.278422594070435 sec\n",
            "Epoch: 115/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 46690: 100%|██████████| 406/406 [00:12<00:00, 32.92it/s, disc_loss=0.211, gen_loss=2.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 115 is 24.563806533813477 sec\n",
            "Epoch: 116/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47096: 100%|██████████| 406/406 [00:12<00:00, 33.06it/s, disc_loss=0.446, gen_loss=1.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 116 is 12.285191774368286 sec\n",
            "Epoch: 117/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47502: 100%|██████████| 406/406 [00:12<00:00, 33.01it/s, disc_loss=0.289, gen_loss=3.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 117 is 12.30537486076355 sec\n",
            "Epoch: 118/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47908: 100%|██████████| 406/406 [00:12<00:00, 33.16it/s, disc_loss=0.104, gen_loss=2.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 118 is 12.249349117279053 sec\n",
            "Epoch: 119/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 48314: 100%|██████████| 406/406 [00:12<00:00, 33.06it/s, disc_loss=0.182, gen_loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 119 is 12.284372568130493 sec\n",
            "Epoch: 120/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 48720: 100%|██████████| 406/406 [00:12<00:00, 32.47it/s, disc_loss=0.0161, gen_loss=2.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 120 is 24.875104427337646 sec\n",
            "Epoch: 121/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49126: 100%|██████████| 406/406 [00:12<00:00, 33.06it/s, disc_loss=0.295, gen_loss=4.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 121 is 12.286281824111938 sec\n",
            "Epoch: 122/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49532: 100%|██████████| 406/406 [00:12<00:00, 32.89it/s, disc_loss=0.438, gen_loss=1.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 122 is 12.349319458007812 sec\n",
            "Epoch: 123/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49938: 100%|██████████| 406/406 [00:12<00:00, 32.80it/s, disc_loss=0.195, gen_loss=3.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 123 is 12.381791353225708 sec\n",
            "Epoch: 124/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 50344: 100%|██████████| 406/406 [00:12<00:00, 33.10it/s, disc_loss=0.316, gen_loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 124 is 12.27008867263794 sec\n",
            "Epoch: 125/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 50750: 100%|██████████| 406/406 [00:12<00:00, 33.01it/s, disc_loss=0.256, gen_loss=2.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 125 is 27.7321720123291 sec\n",
            "Epoch: 126/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51156: 100%|██████████| 406/406 [00:12<00:00, 32.98it/s, disc_loss=0.202, gen_loss=2.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 126 is 12.314094543457031 sec\n",
            "Epoch: 127/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51562: 100%|██████████| 406/406 [00:12<00:00, 33.15it/s, disc_loss=0.154, gen_loss=3.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 127 is 12.252578258514404 sec\n",
            "Epoch: 128/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51968: 100%|██████████| 406/406 [00:12<00:00, 32.46it/s, disc_loss=0.417, gen_loss=3.53]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 128 is 12.515175580978394 sec\n",
            "Epoch: 129/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 52374: 100%|██████████| 406/406 [00:12<00:00, 33.09it/s, disc_loss=0.0387, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 129 is 12.273133516311646 sec\n",
            "Epoch: 130/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 52780: 100%|██████████| 406/406 [00:12<00:00, 33.09it/s, disc_loss=0.299, gen_loss=3.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 130 is 24.382386922836304 sec\n",
            "Epoch: 131/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53186: 100%|██████████| 406/406 [00:12<00:00, 32.92it/s, disc_loss=0.0867, gen_loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 131 is 12.336153268814087 sec\n",
            "Epoch: 132/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53592: 100%|██████████| 406/406 [00:12<00:00, 32.92it/s, disc_loss=0.168, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 132 is 12.336734056472778 sec\n",
            "Epoch: 133/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53998: 100%|██████████| 406/406 [00:12<00:00, 33.12it/s, disc_loss=0.0895, gen_loss=2.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 133 is 12.263509273529053 sec\n",
            "Epoch: 134/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 54404: 100%|██████████| 406/406 [00:12<00:00, 32.85it/s, disc_loss=0.116, gen_loss=2.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 134 is 12.361886978149414 sec\n",
            "Epoch: 135/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 54810: 100%|██████████| 406/406 [00:12<00:00, 33.27it/s, disc_loss=0.22, gen_loss=2.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 135 is 24.44435405731201 sec\n",
            "Epoch: 136/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 55216: 100%|██████████| 406/406 [00:12<00:00, 32.69it/s, disc_loss=0.145, gen_loss=2.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 136 is 12.425877809524536 sec\n",
            "Epoch: 137/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 55622: 100%|██████████| 406/406 [00:12<00:00, 32.47it/s, disc_loss=0.42, gen_loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 137 is 12.507252931594849 sec\n",
            "Epoch: 138/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56028: 100%|██████████| 406/406 [00:12<00:00, 32.70it/s, disc_loss=0.114, gen_loss=3.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 138 is 12.421850681304932 sec\n",
            "Epoch: 139/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56434: 100%|██████████| 406/406 [00:12<00:00, 32.95it/s, disc_loss=0.189, gen_loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 139 is 12.32578420639038 sec\n",
            "Epoch: 140/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56840: 100%|██████████| 406/406 [00:12<00:00, 32.48it/s, disc_loss=0.414, gen_loss=3.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 140 is 24.93795347213745 sec\n",
            "Epoch: 141/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 57246: 100%|██████████| 406/406 [00:12<00:00, 33.06it/s, disc_loss=0.357, gen_loss=1.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 141 is 12.288031578063965 sec\n",
            "Epoch: 142/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 57652: 100%|██████████| 406/406 [00:12<00:00, 32.47it/s, disc_loss=0.233, gen_loss=2.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 142 is 12.509052276611328 sec\n",
            "Epoch: 143/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58058: 100%|██████████| 406/406 [00:12<00:00, 33.18it/s, disc_loss=0.466, gen_loss=3.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 143 is 12.24253511428833 sec\n",
            "Epoch: 144/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58464: 100%|██████████| 406/406 [00:12<00:00, 33.42it/s, disc_loss=0.14, gen_loss=2.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 144 is 12.152795791625977 sec\n",
            "Epoch: 145/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58870: 100%|██████████| 406/406 [00:12<00:00, 32.91it/s, disc_loss=0.445, gen_loss=3.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 145 is 24.57815980911255 sec\n",
            "Epoch: 146/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 59276: 100%|██████████| 406/406 [00:12<00:00, 32.96it/s, disc_loss=0.258, gen_loss=2.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 146 is 12.322377443313599 sec\n",
            "Epoch: 147/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 59682: 100%|██████████| 406/406 [00:12<00:00, 33.14it/s, disc_loss=0.156, gen_loss=2.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 147 is 12.254832744598389 sec\n",
            "Epoch: 148/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60088: 100%|██████████| 406/406 [00:12<00:00, 33.02it/s, disc_loss=0.4, gen_loss=3.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 148 is 12.300954818725586 sec\n",
            "Epoch: 149/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60494: 100%|██████████| 406/406 [00:12<00:00, 32.96it/s, disc_loss=0.385, gen_loss=3.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 149 is 12.323844194412231 sec\n",
            "Epoch: 150/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60900: 100%|██████████| 406/406 [00:12<00:00, 33.08it/s, disc_loss=0.197, gen_loss=2.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 150 is 26.497353553771973 sec\n",
            "Epoch: 151/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 61306: 100%|██████████| 406/406 [00:12<00:00, 32.56it/s, disc_loss=0.131, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 151 is 12.474931240081787 sec\n",
            "Epoch: 152/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 61712: 100%|██████████| 406/406 [00:12<00:00, 33.06it/s, disc_loss=0.302, gen_loss=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 152 is 12.285378694534302 sec\n",
            "Epoch: 153/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62118: 100%|██████████| 406/406 [00:12<00:00, 33.26it/s, disc_loss=0.285, gen_loss=1.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 153 is 12.211250305175781 sec\n",
            "Epoch: 154/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62524: 100%|██████████| 406/406 [00:12<00:00, 33.08it/s, disc_loss=0.21, gen_loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 154 is 12.278136730194092 sec\n",
            "Epoch: 155/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62930: 100%|██████████| 406/406 [00:12<00:00, 33.28it/s, disc_loss=0.712, gen_loss=0.815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 155 is 24.346700191497803 sec\n",
            "Epoch: 156/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 63336: 100%|██████████| 406/406 [00:12<00:00, 33.26it/s, disc_loss=0.226, gen_loss=2.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 156 is 12.212987661361694 sec\n",
            "Epoch: 157/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 63742: 100%|██████████| 406/406 [00:12<00:00, 33.10it/s, disc_loss=0.208, gen_loss=3.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 157 is 12.271507024765015 sec\n",
            "Epoch: 158/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64148: 100%|██████████| 406/406 [00:12<00:00, 33.32it/s, disc_loss=0.204, gen_loss=2.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 158 is 12.190499067306519 sec\n",
            "Epoch: 159/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64554: 100%|██████████| 406/406 [00:12<00:00, 33.17it/s, disc_loss=0.305, gen_loss=2.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 159 is 12.2435941696167 sec\n",
            "Epoch: 160/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64960: 100%|██████████| 406/406 [00:12<00:00, 32.79it/s, disc_loss=0.425, gen_loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 160 is 24.79914402961731 sec\n",
            "Epoch: 161/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 65366: 100%|██████████| 406/406 [00:12<00:00, 32.99it/s, disc_loss=0.0961, gen_loss=3.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 161 is 12.313145875930786 sec\n",
            "Epoch: 162/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 65772: 100%|██████████| 406/406 [00:12<00:00, 33.04it/s, disc_loss=0.213, gen_loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 162 is 12.291733741760254 sec\n",
            "Epoch: 163/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66178: 100%|██████████| 406/406 [00:12<00:00, 32.86it/s, disc_loss=0.191, gen_loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 163 is 12.360942125320435 sec\n",
            "Epoch: 164/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66584: 100%|██████████| 406/406 [00:12<00:00, 33.10it/s, disc_loss=0.21, gen_loss=2.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 164 is 12.271642923355103 sec\n",
            "Epoch: 165/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66990: 100%|██████████| 406/406 [00:12<00:00, 33.00it/s, disc_loss=0.576, gen_loss=3.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 165 is 24.733026266098022 sec\n",
            "Epoch: 166/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 67396: 100%|██████████| 406/406 [00:12<00:00, 32.71it/s, disc_loss=0.0975, gen_loss=2.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 166 is 12.418024063110352 sec\n",
            "Epoch: 167/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 67802: 100%|██████████| 406/406 [00:12<00:00, 33.07it/s, disc_loss=0.331, gen_loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 167 is 12.282601356506348 sec\n",
            "Epoch: 168/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 68208: 100%|██████████| 406/406 [00:12<00:00, 33.44it/s, disc_loss=0.119, gen_loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 168 is 12.146036148071289 sec\n",
            "Epoch: 169/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 68614: 100%|██████████| 406/406 [00:12<00:00, 33.00it/s, disc_loss=0.215, gen_loss=1.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 169 is 12.306116580963135 sec\n",
            "Epoch: 170/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69020: 100%|██████████| 406/406 [00:12<00:00, 33.47it/s, disc_loss=0.0952, gen_loss=3.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 170 is 28.14308738708496 sec\n",
            "Epoch: 171/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69426: 100%|██████████| 406/406 [00:12<00:00, 33.62it/s, disc_loss=0.17, gen_loss=2.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 171 is 12.080689191818237 sec\n",
            "Epoch: 172/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69832: 100%|██████████| 406/406 [00:12<00:00, 33.78it/s, disc_loss=0.176, gen_loss=2.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 172 is 12.023252248764038 sec\n",
            "Epoch: 173/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 70238: 100%|██████████| 406/406 [00:12<00:00, 33.60it/s, disc_loss=0.304, gen_loss=2.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 173 is 12.088168621063232 sec\n",
            "Epoch: 174/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 70644: 100%|██████████| 406/406 [00:12<00:00, 33.24it/s, disc_loss=0.242, gen_loss=2.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 174 is 12.218252897262573 sec\n",
            "Epoch: 175/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71050: 100%|██████████| 406/406 [00:12<00:00, 33.65it/s, disc_loss=0.335, gen_loss=2.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 175 is 24.14968252182007 sec\n",
            "Epoch: 176/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71456: 100%|██████████| 406/406 [00:12<00:00, 33.47it/s, disc_loss=0.0948, gen_loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 176 is 12.137601613998413 sec\n",
            "Epoch: 177/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71862: 100%|██████████| 406/406 [00:12<00:00, 33.68it/s, disc_loss=0.104, gen_loss=2.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 177 is 12.058472156524658 sec\n",
            "Epoch: 178/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 72268: 100%|██████████| 406/406 [00:12<00:00, 33.61it/s, disc_loss=0.0431, gen_loss=2.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 178 is 12.083433866500854 sec\n",
            "Epoch: 179/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 72674: 100%|██████████| 406/406 [00:12<00:00, 33.59it/s, disc_loss=0.379, gen_loss=1.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 179 is 12.089912176132202 sec\n",
            "Epoch: 180/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73080: 100%|██████████| 406/406 [00:12<00:00, 33.54it/s, disc_loss=0.202, gen_loss=2.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 180 is 24.633684873580933 sec\n",
            "Epoch: 181/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73486: 100%|██████████| 406/406 [00:12<00:00, 33.80it/s, disc_loss=0.131, gen_loss=2.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 181 is 12.015926599502563 sec\n",
            "Epoch: 182/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73892: 100%|██████████| 406/406 [00:12<00:00, 33.73it/s, disc_loss=0.19, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 182 is 12.040990829467773 sec\n",
            "Epoch: 183/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 74298: 100%|██████████| 406/406 [00:12<00:00, 33.32it/s, disc_loss=0.141, gen_loss=2.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 183 is 12.192155122756958 sec\n",
            "Epoch: 184/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 74704: 100%|██████████| 406/406 [00:12<00:00, 33.17it/s, disc_loss=0.227, gen_loss=2.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 184 is 12.24233341217041 sec\n",
            "Epoch: 185/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75110: 100%|██████████| 406/406 [00:12<00:00, 33.38it/s, disc_loss=0.156, gen_loss=2.94]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 185 is 24.36439323425293 sec\n",
            "Epoch: 186/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75516: 100%|██████████| 406/406 [00:12<00:00, 32.94it/s, disc_loss=0.344, gen_loss=3.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 186 is 12.330304384231567 sec\n",
            "Epoch: 187/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75922: 100%|██████████| 406/406 [00:12<00:00, 33.18it/s, disc_loss=0.111, gen_loss=2.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 187 is 12.24047064781189 sec\n",
            "Epoch: 188/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 76328: 100%|██████████| 406/406 [00:12<00:00, 33.56it/s, disc_loss=0.263, gen_loss=2.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 188 is 12.10029911994934 sec\n",
            "Epoch: 189/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 76734: 100%|██████████| 406/406 [00:11<00:00, 33.91it/s, disc_loss=0.145, gen_loss=2.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 189 is 11.979701280593872 sec\n",
            "Epoch: 190/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77140: 100%|██████████| 406/406 [00:12<00:00, 33.44it/s, disc_loss=0.463, gen_loss=1.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 190 is 24.151267766952515 sec\n",
            "Epoch: 191/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77546: 100%|██████████| 406/406 [00:12<00:00, 33.45it/s, disc_loss=0.428, gen_loss=3.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 191 is 12.14255428314209 sec\n",
            "Epoch: 192/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77952: 100%|██████████| 406/406 [00:12<00:00, 33.57it/s, disc_loss=0.333, gen_loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 192 is 12.099034786224365 sec\n",
            "Epoch: 193/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 78358: 100%|██████████| 406/406 [00:12<00:00, 33.64it/s, disc_loss=0.321, gen_loss=3.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 193 is 12.072914361953735 sec\n",
            "Epoch: 194/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 78764: 100%|██████████| 406/406 [00:12<00:00, 33.70it/s, disc_loss=0.133, gen_loss=2.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 194 is 12.050076007843018 sec\n",
            "Epoch: 195/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79170: 100%|██████████| 406/406 [00:12<00:00, 33.56it/s, disc_loss=0.238, gen_loss=3.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 195 is 24.079524040222168 sec\n",
            "Epoch: 196/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79576: 100%|██████████| 406/406 [00:12<00:00, 33.59it/s, disc_loss=0.183, gen_loss=3.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 196 is 12.093546867370605 sec\n",
            "Epoch: 197/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79982: 100%|██████████| 406/406 [00:12<00:00, 33.71it/s, disc_loss=0.385, gen_loss=2.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 197 is 12.049917697906494 sec\n",
            "Epoch: 198/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 80388: 100%|██████████| 406/406 [00:12<00:00, 33.52it/s, disc_loss=0.194, gen_loss=2.83]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 198 is 12.115940570831299 sec\n",
            "Epoch: 199/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 80794: 100%|██████████| 406/406 [00:12<00:00, 33.34it/s, disc_loss=0.182, gen_loss=2.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 199 is 12.18082571029663 sec\n",
            "Epoch: 200/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 81200: 100%|██████████| 406/406 [00:12<00:00, 33.43it/s, disc_loss=0.0406, gen_loss=2.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 200 is 26.298611402511597 sec\n"
          ]
        }
      ]
    }
  ]
}