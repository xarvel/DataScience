{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNxs8DP8Y0j0Heak1YfIp/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons -q\n",
        "!rm -rf samples checkpoints\n",
        "!mkdir samples checkpoints"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "b1cec5b8-e264-4caa-95ff-545e94a0fc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Embedding\n",
        "from tensorflow.keras.layers import Wrapper, AveragePooling2D, LeakyReLU, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "from tqdm import tqdm \n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow_addons.layers import SpectralNormalization //not working\n",
        "\n",
        "from google.colab import drive, auth\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "fe129b0f-a0d0-41ad-c48d-f155cdf9ba7b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.9.240.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "DATASET_SIZE = 13262\n",
        "BUFFER_SIZE = DATASET_SIZE\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "SAMPLES_DIR = 'samples'\n",
        "CHECKPOINT_INTERVAL = 50\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "    mean=0.0, stddev=0.02, seed=SEED\n",
        ")\n",
        "weight_regularizer = None\n",
        "weight_regularizer_fully = None"
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset\n",
        "\n",
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SpectralNormalization\n",
        "\n",
        "\n",
        "class SpectralNormalization(Wrapper):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "       layer: tensorflow keras layers (with kernel attribute)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build `Layer`\"\"\"\n",
        "\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "\n",
        "            if not hasattr(self.layer, 'kernel'):\n",
        "                raise ValueError(\n",
        "                    '`SpectralNormalization` must wrap a layer that'\n",
        "                    ' contains a `kernel` for weights')\n",
        "\n",
        "            self.w = self.layer.kernel\n",
        "            self.w_shape = self.w.shape.as_list()\n",
        "            self.u = self.add_weight(\n",
        "                shape=tuple([1, self.w_shape[-1]]),\n",
        "                initializer=k.initializers.TruncatedNormal(stddev=0.02),\n",
        "                name='sn_u',\n",
        "                trainable=False,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        super(SpectralNormalization, self).build()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call `Layer`\"\"\"\n",
        "        # Recompute weights for each forward pass\n",
        "        self._compute_weights()\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        \"\"\"Generate normalized weights.\n",
        "        This method will update the value of self.layer.kernel with the\n",
        "        normalized value, so that the layer is ready for call().\n",
        "        \"\"\"\n",
        "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
        "        eps = 1e-12\n",
        "        _u = tf.identity(self.u)\n",
        "        \n",
        "        _v = tf.matmul(_u, tf.transpose(w_reshaped))\n",
        "        _v = _v / tf.maximum(tf.reduce_sum(_v**2)**0.5, eps)\n",
        "        _u = tf.matmul(_v, w_reshaped)\n",
        "        _u = _u / tf.maximum(tf.reduce_sum(_u**2)**0.5, eps)\n",
        "\n",
        "        self.u.assign(_u)\n",
        "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u))\n",
        "\n",
        "        self.layer.kernel = self.w / sigma\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape(\n",
        "            self.layer.compute_output_shape(input_shape).as_list())"
      ],
      "metadata": {
        "id": "dMyNZbcj_dsD",
        "cellView": "form"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConditionalBatchNormalization\n",
        "\n",
        "class ConditionalBatchNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(ConditionalBatchNormalization, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "   \n",
        "    self.linear_gamma = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_gamma'))\n",
        "    self.linear_beta = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_beta'))\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, x, c, training=False):\n",
        "    x = self.batchnorm(x, training=training)\n",
        "    gamma = self.linear_gamma(c, training=training)  \n",
        "    beta = self.linear_beta(c, training=training)\n",
        "\n",
        "    return x * gamma[:, None, None] + beta[:, None, None]  "
      ],
      "metadata": {
        "id": "d4RfhN_MT1Qv",
        "cellView": "form"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = int(input_shape[-1])\n",
        "\n",
        "        self.conv_theta =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_phi =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_g =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//2, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_attn =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.sigma = self.add_weight('sigma', shape=[], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        batch_size, h, w, in_channels = map(int, x.shape.as_list())\n",
        "        location_num = h*w\n",
        "        downsampled_num = location_num//4\n",
        "\n",
        "        theta = self.conv_theta(x, training=training)\n",
        "        theta = tf.reshape(theta, [batch_size, location_num, in_channels//8])\n",
        "\n",
        "        phi = self.conv_phi(x, training=training)\n",
        "        phi = tf.nn.max_pool(phi, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        phi = tf.reshape(phi, [batch_size, downsampled_num, in_channels//8])\n",
        "\n",
        "        attn = tf.matmul(theta, phi, transpose_b=True)\n",
        "        attn = tf.nn.softmax(attn)\n",
        "\n",
        "        g = self.conv_g(x, training=training)\n",
        "        g = tf.nn.max_pool(g, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        g = tf.reshape(g, [batch_size, downsampled_num, in_channels//2])\n",
        "\n",
        "        attn_g = tf.matmul(attn, g)\n",
        "        attn_g = tf.reshape(attn_g, [batch_size, h, w, in_channels//2])\n",
        "        attn_g = self.conv_attn(attn_g, training=training)\n",
        "\n",
        "        return x + self.sigma * attn_g"
      ],
      "metadata": {
        "id": "MdSa_hc6UCm5",
        "cellView": "form"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DBlock\n",
        "\n",
        "class DBlock(Model):\n",
        "  def __init__(self, channels, downsample=True, preactivation=True):\n",
        "    super(DBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.hidden_channels = self.out_channels \n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.hidden_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.av_pool_1 = AveragePooling2D(padding='same')\n",
        "    self.av_pool_2 = AveragePooling2D(padding='same')\n",
        "    \n",
        "    self.downsample = downsample\n",
        "    self.preactivation = preactivation\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = True if (self.in_channels != self.out_channels) or self.downsample else False\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = tfa.layers.SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "\n",
        "  def shortcut(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "    else:\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      h = self.activation1(x)\n",
        "    else:\n",
        "      h = x    \n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.conv33_2(self.activation2(h), training=training)\n",
        "\n",
        "    if self.downsample:\n",
        "      h = self.av_pool_2(h)     \n",
        "        \n",
        "    return h + self.shortcut(x, training=training)           \n"
      ],
      "metadata": {
        "id": "qPc_lNVnTezv",
        "cellView": "form"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GBlock\n",
        "\n",
        "class GBlock(Model):\n",
        "  def __init__(self, channels):\n",
        "    super(GBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.bn1 = ConditionalBatchNormalization()\n",
        "    self.bn2 = ConditionalBatchNormalization()\n",
        "    self.up_sample_1 = UpSampling2D()\n",
        "    self.up_sample_2 = UpSampling2D()\n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.upsample = True\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = self.in_channels != self.out_channels\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "      \n",
        "  def call(self, x, label, training=False):\n",
        "    h = self.activation1(self.bn1(x, label, training=training))\n",
        "    if self.upsample:\n",
        "      h = self.up_sample_1(h)\n",
        "      x = self.up_sample_2(x)\n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.activation2(self.bn2(h, label, training=training))\n",
        "    h = self.conv33_2(h, training=training)\n",
        "\n",
        "    if self.learnable_sc:       \n",
        "      x = self.conv_sc(x, training=training)\n",
        "\n",
        "    return h + x"
      ],
      "metadata": {
        "id": "-Xi8EUT4TVtc",
        "cellView": "form"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generator\n",
        "\n",
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SpectralNormalization(Dense(4 * 4 * 16 * channels, use_bias=False, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully))\n",
        "    self.reshape = Reshape([4, 4, 16 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(16 * channels)\n",
        "    self.res_block_2 = GBlock(16 * channels)\n",
        "    self.res_block_3 = GBlock(8 * channels)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_4 = GBlock(4 * channels)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.conv = SpectralNormalization(Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.concat = tf.keras.layers.Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=5, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, conds[3], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx",
        "cellView": "form"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(64, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, 120], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "VPNrm_yZUIEW",
        "outputId": "cd0f3b14-0a82-438f-a7f7-902b9775758f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Discriminator\n",
        "\n",
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(1 * channels, downsample=True, preactivation=False)\n",
        "    self.res_block_2 = DBlock(2 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_4 = DBlock(8 * channels, downsample=True, preactivation=True)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_5 = DBlock(16 * channels, downsample=False, preactivation=True)\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.embedding = Embedding(num_classes, 16 * channels, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.linear = SpectralNormalization(\n",
        "       Dense(1, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully)\n",
        "    )\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_5(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr",
        "cellView": "form"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = Discriminator(64, num_classes=NUM_CLASSES)\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkA2GYMW08M",
        "outputId": "2fcd8930-8e31-497d-f4ac-d98b607daa49"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00069148]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per_replica_batch_size = BATCH_SIZE // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=per_replica_batch_size,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_hinge_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  L_D = -tf.reduce_mean(tf.minimum(0., -1.0 + logits_real)) - tf.reduce_mean(tf.minimum(0., -1.0 - logits_fake))\n",
        "\n",
        "  return L_D    \n",
        "\n",
        "def generator_hinge_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "    L_G = -tf.reduce_mean(logits_fake)\n",
        "    return L_G  "
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.0, beta_2=0.999,epsilon=1e-6,)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0.0, beta_2=0.999, epsilon=1e-6)"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = tf.random.truncated_normal((100, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch):\n",
        "  rows = 10\n",
        "  cols = 10\n",
        "\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, 100)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(wspace=0.01, hspace=0)\n",
        "\n",
        "  fig.set_figheight(100)\n",
        "  fig.set_figwidth(100)\n",
        "  fig.set_tight_layout(True)\n",
        " \n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * 10 + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "  plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([per_replica_batch_size, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_hinge_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_hinge_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        " \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "  discriminator_optimizer=discriminator_optimizer,\n",
        "  generator=generator,\n",
        "  discriminator=discriminator)\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "\n",
        "if latest_checkpoint:\n",
        "  first_epoch = int(latest_checkpoint.split(sep='ckpt-')[-1]) * CHECKPOINT_INTERVAL\n",
        "else:\n",
        "  first_epoch = 0\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "def save_checkpoint():\n",
        "  checkpoint_dir = CHECKPOINT_DIR\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "\n",
        "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(first_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch + 1, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    sample_images(epoch)\n",
        "    \n",
        "  if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PE9md58XNvq",
        "outputId": "ce37b4e4-0ad1-4965-8943-a6c91a590a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/414 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall_1:2\", shape=(4,), dtype=int64), values=Tensor(\"PartitionedCall_1:1\", shape=(4, 120), dtype=float32), dense_shape=Tensor(\"PartitionedCall_1:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        }
      ]
    }
  ]
}