{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNHLtt0EnqoiYFphOeTYoAR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons -q\n",
        "!rm -rf samples checkpoints\n",
        "!mkdir samples checkpoints"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XS8zLb4PfNN"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Embedding\n",
        "from tensorflow.keras.layers import Wrapper, AveragePooling2D, LeakyReLU, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "from tqdm import tqdm \n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow_addons.layers import SpectralNormalization //not working\n",
        "\n",
        "from google.colab import drive, auth\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "4b5d290f-e1ba-4f7f-b5f9-8cbcefa697e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function ScopedTFFunction.__del__ at 0x7f7a9e92bc20>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/c_api_util.py\", line 118, in __del__\n",
            "    def __del__(self):\n",
            "KeyboardInterrupt\n",
            "WARNING:tensorflow:TPU system grpc://10.9.240.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "DATASET_SIZE = 13262\n",
        "BUFFER_SIZE = DATASET_SIZE\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "SAMPLES_DIR = 'samples'\n",
        "CHECKPOINT_INTERVAL = 10\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "    mean=0.0, stddev=0.02, seed=SEED\n",
        ")\n",
        "weight_regularizer = None\n",
        "weight_regularizer_fully = None"
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset\n",
        "\n",
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SpectralNormalization\n",
        "\n",
        "\n",
        "class SpectralNormalization(Wrapper):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "       layer: tensorflow keras layers (with kernel attribute)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build `Layer`\"\"\"\n",
        "\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "\n",
        "            if not hasattr(self.layer, 'kernel'):\n",
        "                raise ValueError(\n",
        "                    '`SpectralNormalization` must wrap a layer that'\n",
        "                    ' contains a `kernel` for weights')\n",
        "\n",
        "            self.w = self.layer.kernel\n",
        "            self.w_shape = self.w.shape.as_list()\n",
        "            self.u = self.add_weight(\n",
        "                shape=tuple([1, self.w_shape[-1]]),\n",
        "                initializer=k.initializers.TruncatedNormal(stddev=0.02),\n",
        "                name='sn_u',\n",
        "                trainable=False,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        super(SpectralNormalization, self).build()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call `Layer`\"\"\"\n",
        "        # Recompute weights for each forward pass\n",
        "        self._compute_weights()\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        \"\"\"Generate normalized weights.\n",
        "        This method will update the value of self.layer.kernel with the\n",
        "        normalized value, so that the layer is ready for call().\n",
        "        \"\"\"\n",
        "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
        "        eps = 1e-12\n",
        "        _u = tf.identity(self.u)\n",
        "        \n",
        "        _v = tf.matmul(_u, tf.transpose(w_reshaped))\n",
        "        _v = _v / tf.maximum(tf.reduce_sum(_v**2)**0.5, eps)\n",
        "        _u = tf.matmul(_v, w_reshaped)\n",
        "        _u = _u / tf.maximum(tf.reduce_sum(_u**2)**0.5, eps)\n",
        "\n",
        "        self.u.assign(_u)\n",
        "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u))\n",
        "\n",
        "        self.layer.kernel = self.w / sigma\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape(\n",
        "            self.layer.compute_output_shape(input_shape).as_list())"
      ],
      "metadata": {
        "id": "dMyNZbcj_dsD",
        "cellView": "form"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConditionalBatchNormalization\n",
        "\n",
        "class ConditionalBatchNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(ConditionalBatchNormalization, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "   \n",
        "    self.linear_gamma = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_gamma'))\n",
        "    self.linear_beta = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_beta'))\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, x, c, training=False):\n",
        "    x = self.batchnorm(x, training=training)\n",
        "    gamma = self.linear_gamma(c, training=training)  \n",
        "    beta = self.linear_beta(c, training=training)\n",
        "\n",
        "    return x * gamma[:, None, None] + beta[:, None, None]  "
      ],
      "metadata": {
        "id": "d4RfhN_MT1Qv",
        "cellView": "form"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = int(input_shape[-1])\n",
        "\n",
        "        self.conv_theta =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_phi =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_g =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//2, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_attn =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.sigma = self.add_weight('sigma', shape=[], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        batch_size, h, w, in_channels = map(int, x.shape.as_list())\n",
        "        location_num = h*w\n",
        "        downsampled_num = location_num//4\n",
        "\n",
        "        theta = self.conv_theta(x, training=training)\n",
        "        theta = tf.reshape(theta, [batch_size, location_num, in_channels//8])\n",
        "\n",
        "        phi = self.conv_phi(x, training=training)\n",
        "        phi = tf.nn.max_pool(phi, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        phi = tf.reshape(phi, [batch_size, downsampled_num, in_channels//8])\n",
        "\n",
        "        attn = tf.matmul(theta, phi, transpose_b=True)\n",
        "        attn = tf.nn.softmax(attn)\n",
        "\n",
        "        g = self.conv_g(x, training=training)\n",
        "        g = tf.nn.max_pool(g, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        g = tf.reshape(g, [batch_size, downsampled_num, in_channels//2])\n",
        "\n",
        "        attn_g = tf.matmul(attn, g)\n",
        "        attn_g = tf.reshape(attn_g, [batch_size, h, w, in_channels//2])\n",
        "        attn_g = self.conv_attn(attn_g, training=training)\n",
        "\n",
        "        return x + self.sigma * attn_g"
      ],
      "metadata": {
        "id": "MdSa_hc6UCm5",
        "cellView": "form"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DBlock\n",
        "\n",
        "class DBlock(Model):\n",
        "  def __init__(self, channels, downsample=True, preactivation=True):\n",
        "    super(DBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.hidden_channels = self.out_channels \n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.hidden_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.av_pool_1 = AveragePooling2D(padding='same')\n",
        "    self.av_pool_2 = AveragePooling2D(padding='same')\n",
        "    \n",
        "    self.downsample = downsample\n",
        "    self.preactivation = preactivation\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = True if (self.in_channels != self.out_channels) or self.downsample else False\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = tfa.layers.SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "\n",
        "  def shortcut(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "    else:\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      h = self.activation1(x)\n",
        "    else:\n",
        "      h = x    \n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.conv33_2(self.activation2(h), training=training)\n",
        "\n",
        "    if self.downsample:\n",
        "      h = self.av_pool_2(h)     \n",
        "        \n",
        "    return h + self.shortcut(x, training=training)           \n"
      ],
      "metadata": {
        "id": "qPc_lNVnTezv",
        "cellView": "form"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GBlock\n",
        "\n",
        "class GBlock(Model):\n",
        "  def __init__(self, channels):\n",
        "    super(GBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.bn1 = ConditionalBatchNormalization()\n",
        "    self.bn2 = ConditionalBatchNormalization()\n",
        "    self.up_sample_1 = UpSampling2D()\n",
        "    self.up_sample_2 = UpSampling2D()\n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.upsample = True\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = self.in_channels != self.out_channels\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "      \n",
        "  def call(self, x, label, training=False):\n",
        "    h = self.activation1(self.bn1(x, label, training=training))\n",
        "    if self.upsample:\n",
        "      h = self.up_sample_1(h)\n",
        "      x = self.up_sample_2(x)\n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.activation2(self.bn2(h, label, training=training))\n",
        "    h = self.conv33_2(h, training=training)\n",
        "\n",
        "    if self.learnable_sc:       \n",
        "      x = self.conv_sc(x, training=training)\n",
        "\n",
        "    return h + x"
      ],
      "metadata": {
        "id": "-Xi8EUT4TVtc",
        "cellView": "form"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generator\n",
        "\n",
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SpectralNormalization(Dense(4 * 4 * 16 * channels, use_bias=False, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully))\n",
        "    self.reshape = Reshape([4, 4, 16 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(16 * channels)\n",
        "    self.res_block_2 = GBlock(16 * channels)\n",
        "    self.res_block_3 = GBlock(8 * channels)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_4 = GBlock(4 * channels)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.conv = SpectralNormalization(Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.concat = tf.keras.layers.Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=5, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, conds[3], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(64, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, 120], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "VPNrm_yZUIEW",
        "outputId": "b383ac84-4785-4c86-e60b-719555cd629f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Discriminator\n",
        "\n",
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(1 * channels, downsample=True, preactivation=False)\n",
        "    self.res_block_2 = DBlock(2 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_4 = DBlock(8 * channels, downsample=True, preactivation=True)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_5 = DBlock(16 * channels, downsample=False, preactivation=True)\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.embedding = Embedding(num_classes, 16 * channels, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.linear = SpectralNormalization(\n",
        "       Dense(1, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully)\n",
        "    )\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_5(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr",
        "cellView": "form"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = Discriminator(64, num_classes=NUM_CLASSES)\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkA2GYMW08M",
        "outputId": "dc8f4188-275f-4623-a557-a11301b36f81"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00197093]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per_replica_batch_size = BATCH_SIZE // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=per_replica_batch_size,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_hinge_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  L_D = -tf.reduce_mean(tf.minimum(0., -1.0 + logits_real)) - tf.reduce_mean(tf.minimum(0., -1.0 - logits_fake))\n",
        "\n",
        "  return L_D    \n",
        "\n",
        "def generator_hinge_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "    L_G = -tf.reduce_mean(logits_fake)\n",
        "    return L_G  "
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.0, beta_2=0.999,epsilon=1e-6,)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0.0, beta_2=0.999, epsilon=1e-6)"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = tf.random.truncated_normal((100, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch):\n",
        "  rows = 10\n",
        "  cols = 10\n",
        "\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, 100)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(wspace=0.01, hspace=0)\n",
        "\n",
        "  fig.set_figheight(100)\n",
        "  fig.set_figwidth(100)\n",
        "  fig.set_tight_layout(True)\n",
        " \n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * 10 + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "  plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train_step\n",
        "\n",
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([per_replica_batch_size, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_hinge_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_hinge_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        " \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss"
      ],
      "metadata": {
        "id": "8PE9md58XNvq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checkpoint\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "  discriminator_optimizer=discriminator_optimizer,\n",
        "  generator=generator,\n",
        "  discriminator=discriminator)\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "\n",
        "if latest_checkpoint:\n",
        "  first_epoch = int(latest_checkpoint.split(sep='ckpt-')[-1]) * CHECKPOINT_INTERVAL\n",
        "else:\n",
        "  first_epoch = 0\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "def save_checkpoint():\n",
        "  checkpoint_dir = CHECKPOINT_DIR\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)"
      ],
      "metadata": {
        "id": "JlPAqdghEYZ9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(first_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch + 1, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    sample_images(epoch)\n",
        "    \n",
        "  if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky4ZH-23EiPG",
        "outputId": "082570dc-f6e1-4366-b55f-77c60b34a171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/414 [00:00<?, ?it/s]"
          ]
        }
      ]
    }
  ]
}