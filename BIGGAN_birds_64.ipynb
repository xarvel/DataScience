{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIGGAN_birds_64.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPk88DbSDC0+UQYmzHS7vFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons -q"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "25771679-602d-4423-d06b-60d760425e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Embedding\n",
        "from tensorflow.keras.layers import Wrapper, AveragePooling2D, LeakyReLU, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "from tqdm import tqdm \n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow_addons.layers import SpectralNormalization //not working\n",
        "\n",
        "from google.colab import drive, auth\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sJ3KZ6GQ4GX",
        "outputId": "d3a47405-768d-485b-ad3f-639193b0f0b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "078da607-71db-45ad-c61a-99fc46bc2047"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.44.154.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.44.154.226:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.44.154.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.44.154.226:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "BUFFER_SIZE = 13000\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BIGGAN_birds_64/checkpoints'\n",
        "SAMPLES_DIR = '/content/drive/MyDrive/BIGGAN_birds_64/samples'\n",
        "CHECKPOINT_INTERVAL = 50\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "    mean=0.0, stddev=0.02, seed=SEED\n",
        ")\n",
        "weight_regularizer = None\n",
        "weight_regularizer_fully = None"
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralNormalization(Wrapper):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "       layer: tensorflow keras layers (with kernel attribute)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build `Layer`\"\"\"\n",
        "\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "\n",
        "            if not hasattr(self.layer, 'kernel'):\n",
        "                raise ValueError(\n",
        "                    '`SpectralNormalization` must wrap a layer that'\n",
        "                    ' contains a `kernel` for weights')\n",
        "\n",
        "            self.w = self.layer.kernel\n",
        "            self.w_shape = self.w.shape.as_list()\n",
        "            self.u = self.add_weight(\n",
        "                shape=tuple([1, self.w_shape[-1]]),\n",
        "                initializer=k.initializers.TruncatedNormal(stddev=0.02),\n",
        "                name='sn_u',\n",
        "                trainable=False,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        super(SpectralNormalization, self).build()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call `Layer`\"\"\"\n",
        "        # Recompute weights for each forward pass\n",
        "        self._compute_weights()\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        \"\"\"Generate normalized weights.\n",
        "        This method will update the value of self.layer.kernel with the\n",
        "        normalized value, so that the layer is ready for call().\n",
        "        \"\"\"\n",
        "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
        "        eps = 1e-12\n",
        "        _u = tf.identity(self.u)\n",
        "        \n",
        "        _v = tf.matmul(_u, tf.transpose(w_reshaped))\n",
        "        _v = _v / tf.maximum(tf.reduce_sum(_v**2)**0.5, eps)\n",
        "        _u = tf.matmul(_v, w_reshaped)\n",
        "        _u = _u / tf.maximum(tf.reduce_sum(_u**2)**0.5, eps)\n",
        "\n",
        "        self.u.assign(_u)\n",
        "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u))\n",
        "\n",
        "        self.layer.kernel = self.w / sigma\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape(\n",
        "            self.layer.compute_output_shape(input_shape).as_list())"
      ],
      "metadata": {
        "id": "dMyNZbcj_dsD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConditionalBatchNormalization\n",
        "\n",
        "class ConditionalBatchNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(ConditionalBatchNormalization, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "   \n",
        "    self.linear_gamma = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_gamma'))\n",
        "    self.linear_beta = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_beta'))\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, x, c, training=False):\n",
        "    x = self.batchnorm(x, training=training)\n",
        "    gamma = self.linear_gamma(c, training=training)  \n",
        "    beta = self.linear_beta(c, training=training)\n",
        "\n",
        "    return x * gamma[:, None, None] + beta[:, None, None]  "
      ],
      "metadata": {
        "id": "d4RfhN_MT1Qv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = int(input_shape[-1])\n",
        "\n",
        "        self.conv_theta =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_phi =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_g =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//2, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_attn =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.sigma = self.add_weight('sigma', shape=[], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        batch_size, h, w, in_channels = map(int, x.shape.as_list())\n",
        "        location_num = h*w\n",
        "        downsampled_num = location_num//4\n",
        "\n",
        "        theta = self.conv_theta(x, training=training)\n",
        "        theta = tf.reshape(theta, [batch_size, location_num, in_channels//8])\n",
        "\n",
        "        phi = self.conv_phi(x, training=training)\n",
        "        phi = tf.nn.max_pool(phi, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        phi = tf.reshape(phi, [batch_size, downsampled_num, in_channels//8])\n",
        "\n",
        "        attn = tf.matmul(theta, phi, transpose_b=True)\n",
        "        attn = tf.nn.softmax(attn)\n",
        "\n",
        "        g = self.conv_g(x, training=training)\n",
        "        g = tf.nn.max_pool(g, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        g = tf.reshape(g, [batch_size, downsampled_num, in_channels//2])\n",
        "\n",
        "        attn_g = tf.matmul(attn, g)\n",
        "        attn_g = tf.reshape(attn_g, [batch_size, h, w, in_channels//2])\n",
        "        attn_g = self.conv_attn(attn_g, training=training)\n",
        "\n",
        "        return x + self.sigma * attn_g"
      ],
      "metadata": {
        "id": "MdSa_hc6UCm5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DBlock\n",
        "\n",
        "class DBlock(Model):\n",
        "  def __init__(self, channels, downsample=True, preactivation=True):\n",
        "    super(DBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.hidden_channels = self.out_channels \n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.hidden_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.av_pool_1 = AveragePooling2D(padding='same')\n",
        "    self.av_pool_2 = AveragePooling2D(padding='same')\n",
        "    \n",
        "    self.downsample = downsample\n",
        "    self.preactivation = preactivation\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = True if (self.in_channels != self.out_channels) or self.downsample else False\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = tfa.layers.SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "\n",
        "  def shortcut(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "    else:\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      h = self.activation1(x)\n",
        "    else:\n",
        "      h = x    \n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.conv33_2(self.activation2(h), training=training)\n",
        "\n",
        "    if self.downsample:\n",
        "      h = self.av_pool_2(h)     \n",
        "        \n",
        "    return h + self.shortcut(x, training=training)           \n"
      ],
      "metadata": {
        "id": "qPc_lNVnTezv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GBlock\n",
        "\n",
        "class GBlock(Model):\n",
        "  def __init__(self, channels):\n",
        "    super(GBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.bn1 = ConditionalBatchNormalization()\n",
        "    self.bn2 = ConditionalBatchNormalization()\n",
        "    self.up_sample_1 = UpSampling2D()\n",
        "    self.up_sample_2 = UpSampling2D()\n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.upsample = True\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = self.in_channels != self.out_channels\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "      \n",
        "  def call(self, x, label, training=False):\n",
        "    h = self.activation1(self.bn1(x, label, training=training))\n",
        "    if self.upsample:\n",
        "      h = self.up_sample_1(h)\n",
        "      x = self.up_sample_2(x)\n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.activation2(self.bn2(h, label, training=training))\n",
        "    h = self.conv33_2(h, training=training)\n",
        "\n",
        "    if self.learnable_sc:       \n",
        "      x = self.conv_sc(x, training=training)\n",
        "\n",
        "    return h + x"
      ],
      "metadata": {
        "id": "-Xi8EUT4TVtc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SpectralNormalization(Dense(4 * 4 * 16 * channels, use_bias=False, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully))\n",
        "    self.reshape = Reshape([4, 4, 16 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(16 * channels)\n",
        "    self.res_block_2 = GBlock(16 * channels)\n",
        "    self.res_block_3 = GBlock(8 * channels)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_4 = GBlock(4 * channels)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.conv = SpectralNormalization(Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.concat = tf.keras.layers.Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=5, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, conds[3], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(64, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, 120], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "VPNrm_yZUIEW",
        "outputId": "e544f53a-edd6-467e-a461-16103ab85c82"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 144) <dtype: 'float32'>\n",
            "(1, 144) <dtype: 'float32'>\n",
            "(1, 64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(1 * channels, downsample=True, preactivation=False)\n",
        "    self.res_block_2 = DBlock(2 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_4 = DBlock(8 * channels, downsample=True, preactivation=True)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_5 = DBlock(16 * channels, downsample=False, preactivation=True)\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.embedding = Embedding(num_classes, 16 * channels, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.linear = SpectralNormalization(\n",
        "       Dense(1, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully)\n",
        "    )\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_5(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = Discriminator(64, num_classes=NUM_CLASSES)\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkA2GYMW08M",
        "outputId": "3551fb33-5a91-4939-d9f0-b301acaa16b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.00157929]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per_replica_batch_size = BATCH_SIZE // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=per_replica_batch_size,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_hinge_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  L_D = -tf.reduce_mean(tf.minimum(0., -1.0 + logits_real)) - tf.reduce_mean(tf.minimum(0., -1.0 - logits_fake))\n",
        "\n",
        "  return L_D    \n",
        "\n",
        "def generator_hinge_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "    L_G = -tf.reduce_mean(logits_fake)\n",
        "    return L_G  "
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.0, beta_2=0.999,epsilon=1e-6,)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0.0, beta_2=0.999, epsilon=1e-6)"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = tf.random.truncated_normal((100, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch):\n",
        "  rows = 10\n",
        "  cols = 10\n",
        "\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, 100)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(wspace=0.01, hspace=0)\n",
        "\n",
        "  fig.set_figheight(100)\n",
        "  fig.set_figwidth(100)\n",
        "  fig.set_tight_layout(True)\n",
        " \n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * 10 + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "  plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([per_replica_batch_size, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_hinge_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_hinge_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        " \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "  discriminator_optimizer=discriminator_optimizer,\n",
        "  generator=generator,\n",
        "  discriminator=discriminator)\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "\n",
        "if latest_checkpoint:\n",
        "  first_epoch = int(latest_checkpoint.split(sep='ckpt-')[-1]) * CHECKPOINT_INTERVAL\n",
        "else:\n",
        "  first_epoch = 0\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "def save_checkpoint():\n",
        "  checkpoint_dir = CHECKPOINT_DIR\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "\n",
        "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(first_epoch, EPOCHS):\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch + 1, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    sample_images(epoch)\n",
        "    \n",
        "  if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PE9md58XNvq",
        "outputId": "f92d5a1c-1575-4870-fb8c-e947b2e8c90f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/406 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 144) <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall_1:2\", shape=(4,), dtype=int64), values=Tensor(\"PartitionedCall_1:1\", shape=(4, 120), dtype=float32), dense_shape=Tensor(\"PartitionedCall_1:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_1:0\", shape=(8,), dtype=int64), values=Tensor(\"concat:0\", shape=(8, 1024), dtype=float32), dense_shape=Tensor(\"PartitionedCall_2:59\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 144) <dtype: 'float32'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 406: 100%|██████████| 406/406 [05:09<00:00,  1.31it/s, disc_loss=0.449, gen_loss=0.681]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 309.121218919754 sec\n",
            "Epoch: 2/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 812: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=1.79, gen_loss=-.235]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 2 is 34.40639615058899 sec\n",
            "Epoch: 3/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1218: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.0278, gen_loss=1.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 3 is 34.505966901779175 sec\n",
            "Epoch: 4/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1624: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.0861, gen_loss=2.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 4 is 34.553088426589966 sec\n",
            "Epoch: 5/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2030: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.164, gen_loss=1.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 144) <dtype: 'float32'>\n",
            "Time for epoch 5 is 53.30950593948364 sec\n",
            "Epoch: 6/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2436: 100%|██████████| 406/406 [00:34<00:00, 11.71it/s, disc_loss=1.47, gen_loss=2.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 6 is 34.66800904273987 sec\n",
            "Epoch: 7/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 2842: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.58, gen_loss=1.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 7 is 34.612056016922 sec\n",
            "Epoch: 8/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 3248: 100%|██████████| 406/406 [00:34<00:00, 11.69it/s, disc_loss=0.115, gen_loss=1.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 8 is 34.72279453277588 sec\n",
            "Epoch: 9/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 3654: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.812, gen_loss=1.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 9 is 34.44492530822754 sec\n",
            "Epoch: 10/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4060: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.5, gen_loss=0.918]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 10 is 50.075071573257446 sec\n",
            "Epoch: 11/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4466: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.381, gen_loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 11 is 34.59032368659973 sec\n",
            "Epoch: 12/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 4872: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.176, gen_loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 12 is 34.59195852279663 sec\n",
            "Epoch: 13/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 5278: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.0946, gen_loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 13 is 34.49999761581421 sec\n",
            "Epoch: 14/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 5684: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.527, gen_loss=1.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 14 is 34.57532501220703 sec\n",
            "Epoch: 15/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6090: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.366, gen_loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 15 is 49.85042762756348 sec\n",
            "Epoch: 16/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6496: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.26, gen_loss=1.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 16 is 34.396302461624146 sec\n",
            "Epoch: 17/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 6902: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.468, gen_loss=1.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 17 is 34.46466779708862 sec\n",
            "Epoch: 18/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 7308: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.194, gen_loss=2.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 18 is 34.53201341629028 sec\n",
            "Epoch: 19/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 7714: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.361, gen_loss=1.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 19 is 34.54343557357788 sec\n",
            "Epoch: 20/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8120: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.422, gen_loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 20 is 49.906726360321045 sec\n",
            "Epoch: 21/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8526: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.116, gen_loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 21 is 34.55859160423279 sec\n",
            "Epoch: 22/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 8932: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.269, gen_loss=1.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 22 is 34.59048342704773 sec\n",
            "Epoch: 23/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 9338: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.46, gen_loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 23 is 34.52670097351074 sec\n",
            "Epoch: 24/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 9744: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.339, gen_loss=2.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 24 is 34.561224699020386 sec\n",
            "Epoch: 25/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10150: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.321, gen_loss=1.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 25 is 53.16251349449158 sec\n",
            "Epoch: 26/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10556: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.435, gen_loss=2.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 26 is 34.50520849227905 sec\n",
            "Epoch: 27/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 10962: 100%|██████████| 406/406 [00:34<00:00, 11.69it/s, disc_loss=0.0569, gen_loss=2.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 27 is 34.75027847290039 sec\n",
            "Epoch: 28/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 11368: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.306, gen_loss=2.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 28 is 34.55192184448242 sec\n",
            "Epoch: 29/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 11774: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.331, gen_loss=2.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 29 is 34.473530769348145 sec\n",
            "Epoch: 30/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12180: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.175, gen_loss=1.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 30 is 49.875911235809326 sec\n",
            "Epoch: 31/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12586: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.443, gen_loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 31 is 34.471760988235474 sec\n",
            "Epoch: 32/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 12992: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.501, gen_loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 32 is 34.43138074874878 sec\n",
            "Epoch: 33/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 13398: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.269, gen_loss=2.66]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 33 is 34.55643010139465 sec\n",
            "Epoch: 34/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 13804: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.662, gen_loss=2.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 34 is 34.56840658187866 sec\n",
            "Epoch: 35/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 14210: 100%|██████████| 406/406 [00:34<00:00, 11.71it/s, disc_loss=0.378, gen_loss=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 35 is 50.02056050300598 sec\n",
            "Epoch: 36/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 14616: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.285, gen_loss=2.37]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 36 is 34.4671905040741 sec\n",
            "Epoch: 37/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15022: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.808, gen_loss=0.466]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 37 is 34.532219886779785 sec\n",
            "Epoch: 38/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15428: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.221, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 38 is 34.49167060852051 sec\n",
            "Epoch: 39/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 15834: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.13, gen_loss=2.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 39 is 34.51211762428284 sec\n",
            "Epoch: 40/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 16240: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.0352, gen_loss=2.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 40 is 49.65102696418762 sec\n",
            "Epoch: 41/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 16646: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.337, gen_loss=1.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 41 is 34.39122486114502 sec\n",
            "Epoch: 42/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17052: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.441, gen_loss=2.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 42 is 34.39780378341675 sec\n",
            "Epoch: 43/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17458: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.565, gen_loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 43 is 34.47157621383667 sec\n",
            "Epoch: 44/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 17864: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.248, gen_loss=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 44 is 34.45146369934082 sec\n",
            "Epoch: 45/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 18270: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.388, gen_loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 45 is 50.1147096157074 sec\n",
            "Epoch: 46/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 18676: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.076, gen_loss=2.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 46 is 34.4668984413147 sec\n",
            "Epoch: 47/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19082: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.338, gen_loss=3.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 47 is 34.53898644447327 sec\n",
            "Epoch: 48/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19488: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.246, gen_loss=2.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 48 is 34.58586597442627 sec\n",
            "Epoch: 49/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 19894: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.427, gen_loss=3.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 49 is 34.58048129081726 sec\n",
            "Epoch: 50/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 20300: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.093, gen_loss=2.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 50 is 58.83386278152466 sec\n",
            "Epoch: 51/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 20706: 100%|██████████| 406/406 [00:35<00:00, 11.33it/s, disc_loss=0.189, gen_loss=1.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 51 is 35.82750678062439 sec\n",
            "Epoch: 52/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21112: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.42, gen_loss=1.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 52 is 34.43753695487976 sec\n",
            "Epoch: 53/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21518: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.101, gen_loss=2.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 53 is 34.4011914730072 sec\n",
            "Epoch: 54/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 21924: 100%|██████████| 406/406 [00:34<00:00, 11.82it/s, disc_loss=0.263, gen_loss=2.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 54 is 34.34171438217163 sec\n",
            "Epoch: 55/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 22330: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.294, gen_loss=2.87]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 55 is 48.94876408576965 sec\n",
            "Epoch: 56/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 22736: 100%|██████████| 406/406 [00:34<00:00, 11.82it/s, disc_loss=0.336, gen_loss=2.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 56 is 34.35047674179077 sec\n",
            "Epoch: 57/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23142: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.383, gen_loss=2.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 57 is 34.382466554641724 sec\n",
            "Epoch: 58/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23548: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.318, gen_loss=2.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 58 is 34.404181241989136 sec\n",
            "Epoch: 59/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 23954: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.451, gen_loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 59 is 34.44511914253235 sec\n",
            "Epoch: 60/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 24360: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.353, gen_loss=2.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 60 is 49.83947157859802 sec\n",
            "Epoch: 61/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 24766: 100%|██████████| 406/406 [00:34<00:00, 11.83it/s, disc_loss=0.358, gen_loss=1.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 61 is 34.32261896133423 sec\n",
            "Epoch: 62/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25172: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.275, gen_loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 62 is 34.44057083129883 sec\n",
            "Epoch: 63/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25578: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.384, gen_loss=1.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 63 is 34.546976804733276 sec\n",
            "Epoch: 64/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 25984: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=1.01, gen_loss=4.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 64 is 34.445144176483154 sec\n",
            "Epoch: 65/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 26390: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.135, gen_loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 65 is 49.353358030319214 sec\n",
            "Epoch: 66/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 26796: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.327, gen_loss=2.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 66 is 34.51746344566345 sec\n",
            "Epoch: 67/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 27202: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.107, gen_loss=2.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 67 is 34.43967318534851 sec\n",
            "Epoch: 68/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 27608: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.265, gen_loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 68 is 34.492098569869995 sec\n",
            "Epoch: 69/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28014: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.338, gen_loss=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 69 is 34.56231951713562 sec\n",
            "Epoch: 70/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28420: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.241, gen_loss=2.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 70 is 49.57423639297485 sec\n",
            "Epoch: 71/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 28826: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.337, gen_loss=1.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 71 is 34.57858991622925 sec\n",
            "Epoch: 72/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 29232: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.222, gen_loss=2.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 72 is 34.41341471672058 sec\n",
            "Epoch: 73/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 29638: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.142, gen_loss=2.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 73 is 34.47278666496277 sec\n",
            "Epoch: 74/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30044: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.268, gen_loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 74 is 34.48783874511719 sec\n",
            "Epoch: 75/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30450: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.217, gen_loss=2.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 75 is 49.82944345474243 sec\n",
            "Epoch: 76/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 30856: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.11, gen_loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 76 is 34.50464200973511 sec\n",
            "Epoch: 77/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 31262: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.331, gen_loss=1.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 77 is 34.59647297859192 sec\n",
            "Epoch: 78/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 31668: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.201, gen_loss=1.97]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 78 is 34.58043551445007 sec\n",
            "Epoch: 79/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32074: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.293, gen_loss=2.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 79 is 34.42579960823059 sec\n",
            "Epoch: 80/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32480: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.502, gen_loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 80 is 50.01317763328552 sec\n",
            "Epoch: 81/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 32886: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.332, gen_loss=2.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 81 is 34.37487053871155 sec\n",
            "Epoch: 82/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 33292: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.149, gen_loss=1.87]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 82 is 34.594778060913086 sec\n",
            "Epoch: 83/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 33698: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.335, gen_loss=1.65]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 83 is 34.6568877696991 sec\n",
            "Epoch: 84/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34104: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.549, gen_loss=3.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 84 is 34.509355545043945 sec\n",
            "Epoch: 85/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34510: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.303, gen_loss=3.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 85 is 52.84213852882385 sec\n",
            "Epoch: 86/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 34916: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.412, gen_loss=1.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 86 is 34.53010153770447 sec\n",
            "Epoch: 87/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 35322: 100%|██████████| 406/406 [00:34<00:00, 11.82it/s, disc_loss=0.283, gen_loss=1.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 87 is 34.36250686645508 sec\n",
            "Epoch: 88/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 35728: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.201, gen_loss=2.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 88 is 34.554115772247314 sec\n",
            "Epoch: 89/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36134: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.249, gen_loss=3.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 89 is 34.497870206832886 sec\n",
            "Epoch: 90/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36540: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.166, gen_loss=2.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 90 is 50.07280135154724 sec\n",
            "Epoch: 91/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 36946: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.101, gen_loss=2.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 91 is 34.433759450912476 sec\n",
            "Epoch: 92/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 37352: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.415, gen_loss=4.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 92 is 34.53683161735535 sec\n",
            "Epoch: 93/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 37758: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.176, gen_loss=2.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 93 is 34.49694490432739 sec\n",
            "Epoch: 94/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38164: 100%|██████████| 406/406 [00:34<00:00, 11.70it/s, disc_loss=0.0339, gen_loss=2.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 94 is 34.70094871520996 sec\n",
            "Epoch: 95/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38570: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.181, gen_loss=3.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 95 is 50.11707425117493 sec\n",
            "Epoch: 96/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 38976: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.385, gen_loss=1.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 96 is 34.40175151824951 sec\n",
            "Epoch: 97/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 39382: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.187, gen_loss=3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 97 is 34.58119559288025 sec\n",
            "Epoch: 98/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 39788: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.316, gen_loss=1.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 98 is 34.46426963806152 sec\n",
            "Epoch: 99/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 40194: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.184, gen_loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 99 is 34.48101353645325 sec\n",
            "Epoch: 100/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 40600: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.205, gen_loss=2.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 100 is 57.42152953147888 sec\n",
            "Epoch: 101/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41006: 100%|██████████| 406/406 [00:36<00:00, 11.22it/s, disc_loss=0.117, gen_loss=2.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 101 is 36.179309129714966 sec\n",
            "Epoch: 102/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41412: 100%|██████████| 406/406 [00:34<00:00, 11.70it/s, disc_loss=0.0729, gen_loss=3.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 102 is 34.71779417991638 sec\n",
            "Epoch: 103/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 41818: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.132, gen_loss=2.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 103 is 34.6575710773468 sec\n",
            "Epoch: 104/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 42224: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.532, gen_loss=1.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 104 is 34.46467566490173 sec\n",
            "Epoch: 105/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 42630: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.0269, gen_loss=3.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 105 is 49.80384540557861 sec\n",
            "Epoch: 106/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43036: 100%|██████████| 406/406 [00:34<00:00, 11.71it/s, disc_loss=0.576, gen_loss=3.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 106 is 34.66719913482666 sec\n",
            "Epoch: 107/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43442: 100%|██████████| 406/406 [00:34<00:00, 11.70it/s, disc_loss=0.115, gen_loss=2.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 107 is 34.69447302818298 sec\n",
            "Epoch: 108/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 43848: 100%|██████████| 406/406 [00:34<00:00, 11.68it/s, disc_loss=0.554, gen_loss=3.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 108 is 34.7696168422699 sec\n",
            "Epoch: 109/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 44254: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.219, gen_loss=2.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 109 is 34.556812047958374 sec\n",
            "Epoch: 110/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 44660: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.322, gen_loss=3.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 110 is 49.84401822090149 sec\n",
            "Epoch: 111/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45066: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.195, gen_loss=3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 111 is 34.50229835510254 sec\n",
            "Epoch: 112/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45472: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.419, gen_loss=3.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 112 is 34.64598083496094 sec\n",
            "Epoch: 113/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 45878: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.199, gen_loss=2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 113 is 34.528794288635254 sec\n",
            "Epoch: 114/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 46284: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.466, gen_loss=2.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 114 is 34.49004578590393 sec\n",
            "Epoch: 115/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 46690: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.197, gen_loss=2.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 115 is 49.947922706604004 sec\n",
            "Epoch: 116/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47096: 100%|██████████| 406/406 [00:34<00:00, 11.69it/s, disc_loss=0.266, gen_loss=2.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 116 is 34.7400643825531 sec\n",
            "Epoch: 117/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47502: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.197, gen_loss=2.87]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 117 is 34.64690613746643 sec\n",
            "Epoch: 118/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 47908: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.199, gen_loss=1.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 118 is 34.51972150802612 sec\n",
            "Epoch: 119/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 48314: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.225, gen_loss=3.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 119 is 34.55028462409973 sec\n",
            "Epoch: 120/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 48720: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.116, gen_loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 120 is 49.629753828048706 sec\n",
            "Epoch: 121/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49126: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.255, gen_loss=2.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 121 is 34.522218465805054 sec\n",
            "Epoch: 122/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49532: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.323, gen_loss=2.69]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 122 is 34.53257441520691 sec\n",
            "Epoch: 123/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 49938: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.176, gen_loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 123 is 34.55872416496277 sec\n",
            "Epoch: 124/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 50344: 100%|██████████| 406/406 [00:34<00:00, 11.83it/s, disc_loss=0.048, gen_loss=3.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 124 is 34.311190605163574 sec\n",
            "Epoch: 125/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 50750: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.233, gen_loss=2.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 125 is 52.91820788383484 sec\n",
            "Epoch: 126/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51156: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.225, gen_loss=3.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 126 is 34.48774528503418 sec\n",
            "Epoch: 127/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51562: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.489, gen_loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 127 is 34.60978174209595 sec\n",
            "Epoch: 128/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 51968: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.147, gen_loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 128 is 34.586419105529785 sec\n",
            "Epoch: 129/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 52374: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.0856, gen_loss=1.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 129 is 34.63730549812317 sec\n",
            "Epoch: 130/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 52780: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.217, gen_loss=2.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 130 is 49.958730936050415 sec\n",
            "Epoch: 131/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53186: 100%|██████████| 406/406 [00:34<00:00, 11.70it/s, disc_loss=0.066, gen_loss=2.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 131 is 34.711647272109985 sec\n",
            "Epoch: 132/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53592: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.18, gen_loss=2.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 132 is 34.62217426300049 sec\n",
            "Epoch: 133/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 53998: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.343, gen_loss=2.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 133 is 34.55394268035889 sec\n",
            "Epoch: 134/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 54404: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.154, gen_loss=2.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 134 is 34.593971729278564 sec\n",
            "Epoch: 135/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 54810: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.341, gen_loss=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 135 is 49.72690033912659 sec\n",
            "Epoch: 136/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 55216: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.143, gen_loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 136 is 34.47995662689209 sec\n",
            "Epoch: 137/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 55622: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.4, gen_loss=3.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 137 is 34.53226447105408 sec\n",
            "Epoch: 138/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56028: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.282, gen_loss=2.25]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 138 is 34.47100758552551 sec\n",
            "Epoch: 139/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56434: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.289, gen_loss=1.68]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 139 is 34.57716202735901 sec\n",
            "Epoch: 140/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 56840: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.27, gen_loss=2.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 140 is 49.68809413909912 sec\n",
            "Epoch: 141/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 57246: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.321, gen_loss=1.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 141 is 34.468048334121704 sec\n",
            "Epoch: 142/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 57652: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.333, gen_loss=2.98]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 142 is 34.48884892463684 sec\n",
            "Epoch: 143/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58058: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.233, gen_loss=2.85]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 143 is 34.619224071502686 sec\n",
            "Epoch: 144/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58464: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.247, gen_loss=3.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 144 is 34.608861446380615 sec\n",
            "Epoch: 145/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 58870: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.42, gen_loss=1.55]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 145 is 50.23555660247803 sec\n",
            "Epoch: 146/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 59276: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.282, gen_loss=1.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 146 is 34.45797920227051 sec\n",
            "Epoch: 147/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 59682: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.374, gen_loss=2.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 147 is 34.4968523979187 sec\n",
            "Epoch: 148/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60088: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.235, gen_loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 148 is 34.528194189071655 sec\n",
            "Epoch: 149/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60494: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.49, gen_loss=3.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 149 is 34.48094940185547 sec\n",
            "Epoch: 150/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 60900: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.15, gen_loss=2.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 150 is 55.50764346122742 sec\n",
            "Epoch: 151/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 61306: 100%|██████████| 406/406 [00:37<00:00, 10.91it/s, disc_loss=0.258, gen_loss=2.93]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 151 is 37.209025621414185 sec\n",
            "Epoch: 152/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 61712: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.416, gen_loss=1.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 152 is 34.48692083358765 sec\n",
            "Epoch: 153/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62118: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.216, gen_loss=2.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 153 is 34.535261154174805 sec\n",
            "Epoch: 154/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62524: 100%|██████████| 406/406 [00:34<00:00, 11.81it/s, disc_loss=0.547, gen_loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 154 is 34.39251446723938 sec\n",
            "Epoch: 155/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 62930: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.339, gen_loss=3.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 155 is 49.05656433105469 sec\n",
            "Epoch: 156/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 63336: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.557, gen_loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 156 is 34.44534158706665 sec\n",
            "Epoch: 157/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 63742: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.412, gen_loss=2.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 157 is 34.410419940948486 sec\n",
            "Epoch: 158/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64148: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.186, gen_loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 158 is 34.456003189086914 sec\n",
            "Epoch: 159/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64554: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.378, gen_loss=1.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 159 is 34.569616079330444 sec\n",
            "Epoch: 160/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 64960: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.31, gen_loss=1.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 160 is 49.4215669631958 sec\n",
            "Epoch: 161/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 65366: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.262, gen_loss=2.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 161 is 34.440932750701904 sec\n",
            "Epoch: 162/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 65772: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.514, gen_loss=3.41]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 162 is 34.65616512298584 sec\n",
            "Epoch: 163/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66178: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.671, gen_loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 163 is 34.63213109970093 sec\n",
            "Epoch: 164/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66584: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.561, gen_loss=1.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 164 is 34.55670094490051 sec\n",
            "Epoch: 165/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 66990: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.291, gen_loss=2.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 165 is 49.38388156890869 sec\n",
            "Epoch: 166/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 67396: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.151, gen_loss=2.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 166 is 34.48409700393677 sec\n",
            "Epoch: 167/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 67802: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.375, gen_loss=3.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 167 is 34.45842909812927 sec\n",
            "Epoch: 168/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 68208: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.239, gen_loss=2.57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 168 is 34.428008794784546 sec\n",
            "Epoch: 169/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 68614: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.36, gen_loss=2.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 169 is 34.453333616256714 sec\n",
            "Epoch: 170/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69020: 100%|██████████| 406/406 [00:34<00:00, 11.77it/s, disc_loss=0.129, gen_loss=2.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 170 is 49.137322664260864 sec\n",
            "Epoch: 171/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69426: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.57, gen_loss=1.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 171 is 34.4397349357605 sec\n",
            "Epoch: 172/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 69832: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.442, gen_loss=2.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 172 is 34.57062101364136 sec\n",
            "Epoch: 173/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 70238: 100%|██████████| 406/406 [00:34<00:00, 11.82it/s, disc_loss=0.146, gen_loss=2.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 173 is 34.348416805267334 sec\n",
            "Epoch: 174/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 70644: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.386, gen_loss=2.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 174 is 34.43201041221619 sec\n",
            "Epoch: 175/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71050: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.389, gen_loss=2.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 175 is 53.615480184555054 sec\n",
            "Epoch: 176/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71456: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.564, gen_loss=2.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 176 is 34.43371105194092 sec\n",
            "Epoch: 177/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 71862: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.397, gen_loss=1.45]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 177 is 34.564921140670776 sec\n",
            "Epoch: 178/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 72268: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.246, gen_loss=2.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 178 is 34.62421655654907 sec\n",
            "Epoch: 179/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 72674: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.443, gen_loss=2.77]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 179 is 34.5458459854126 sec\n",
            "Epoch: 180/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73080: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.274, gen_loss=1.73]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 180 is 49.335734844207764 sec\n",
            "Epoch: 181/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73486: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.292, gen_loss=2.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 181 is 34.613922357559204 sec\n",
            "Epoch: 182/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 73892: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.531, gen_loss=0.933]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 182 is 34.61489796638489 sec\n",
            "Epoch: 183/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 74298: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.515, gen_loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 183 is 34.438082218170166 sec\n",
            "Epoch: 184/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 74704: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.45, gen_loss=2.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 184 is 34.5238618850708 sec\n",
            "Epoch: 185/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75110: 100%|██████████| 406/406 [00:34<00:00, 11.73it/s, disc_loss=0.336, gen_loss=2.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 185 is 49.373226165771484 sec\n",
            "Epoch: 186/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75516: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.342, gen_loss=1.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 186 is 34.558359146118164 sec\n",
            "Epoch: 187/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 75922: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.276, gen_loss=2.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 187 is 34.47370409965515 sec\n",
            "Epoch: 188/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 76328: 100%|██████████| 406/406 [00:34<00:00, 11.78it/s, disc_loss=0.163, gen_loss=2.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 188 is 34.48085355758667 sec\n",
            "Epoch: 189/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 76734: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.481, gen_loss=2.88]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 189 is 34.560556411743164 sec\n",
            "Epoch: 190/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77140: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.347, gen_loss=1.63]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 190 is 49.47488045692444 sec\n",
            "Epoch: 191/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77546: 100%|██████████| 406/406 [00:34<00:00, 11.74it/s, disc_loss=0.377, gen_loss=3.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 191 is 34.59457015991211 sec\n",
            "Epoch: 192/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 77952: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.829, gen_loss=0.759]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 192 is 34.45130491256714 sec\n",
            "Epoch: 193/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 78358: 100%|██████████| 406/406 [00:34<00:00, 11.72it/s, disc_loss=0.262, gen_loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 193 is 34.64344072341919 sec\n",
            "Epoch: 194/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 78764: 100%|██████████| 406/406 [00:34<00:00, 11.76it/s, disc_loss=0.188, gen_loss=2.49]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 194 is 34.53882694244385 sec\n",
            "Epoch: 195/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79170: 100%|██████████| 406/406 [00:34<00:00, 11.75it/s, disc_loss=0.373, gen_loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 195 is 49.338892221450806 sec\n",
            "Epoch: 196/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79576: 100%|██████████| 406/406 [00:34<00:00, 11.84it/s, disc_loss=0.362, gen_loss=1.91]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 196 is 34.30239224433899 sec\n",
            "Epoch: 197/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 79982: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.24, gen_loss=2.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 197 is 34.42718148231506 sec\n",
            "Epoch: 198/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 80388: 100%|██████████| 406/406 [00:34<00:00, 11.79it/s, disc_loss=0.294, gen_loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 198 is 34.43481421470642 sec\n",
            "Epoch: 199/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 80794: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.462, gen_loss=2.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 199 is 34.41056704521179 sec\n",
            "Epoch: 200/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 81200: 100%|██████████| 406/406 [00:34<00:00, 11.80it/s, disc_loss=0.123, gen_loss=2.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 200 is 55.35598039627075 sec\n"
          ]
        }
      ]
    }
  ]
}