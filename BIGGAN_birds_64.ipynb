{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMfmwD/Lo5SLBYAHMie2KXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xarvel/DataScience/blob/master/BIGGAN_birds_64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gan tensorflow-addons -q"
      ],
      "metadata": {
        "id": "5Mw4l2saP3EF"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XS8zLb4PfNN",
        "outputId": "9ac85e30-e0b8-4dcb-d2b9-2da83ff319f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.keras as k\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Embedding\n",
        "from tensorflow.keras.layers import Wrapper, AveragePooling2D, LeakyReLU, BatchNormalization, UpSampling2D, GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "from tqdm import tqdm \n",
        "import tensorflow_addons as tfa\n",
        "# from tensorflow_addons.layers import SpectralNormalization //not working\n",
        "\n",
        "from google.colab import drive, auth\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TPU CONFIG\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ92cQiXSb-D",
        "outputId": "672dd773-b39d-49c7-8f25-9ba139665e3d"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.9.240.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CONSTS\n",
        "\n",
        "IMAGE_SIZE = 64\n",
        "DATASET_SIZE = 13262\n",
        "BUFFER_SIZE = DATASET_SIZE\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 200\n",
        "LATENT_DIM = 120\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "SAMPLES_DIR = 'samples'\n",
        "CHECKPOINT_INTERVAL = 10\n",
        "SEED = 1\n",
        "NUM_CLASSES = 100\n",
        "TFRECORD_PATH = 'gs://brids-xarvel/*.tfrec'\n"
      ],
      "metadata": {
        "id": "4-YzvGP1RLPX"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = tf.keras.initializers.RandomNormal(\n",
        "    mean=0.0, stddev=0.02, seed=SEED\n",
        ")\n",
        "weight_regularizer = None\n",
        "weight_regularizer_fully = None"
      ],
      "metadata": {
        "id": "HWV7ZA6nUthy"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset\n",
        "\n",
        "def preprocess_image(img):\n",
        "    return tf.cast(img, tf.float32) / 127.5 - 1.\n",
        "\n",
        "def get_tfrecord_dataset(\n",
        "    batch_size: int,\n",
        "    tfrecord_path: str,\n",
        "    is_training: bool,\n",
        "    *,\n",
        "    image_size: int,\n",
        "):\n",
        "    def parse_example(proto):\n",
        "        features = {\n",
        "          \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "          'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'channels': tf.io.FixedLenFeature([], tf.int64),\n",
        "          'label_text': tf.io.FixedLenFeature([], tf.string), \n",
        "          'label_onehot':  tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True),\n",
        "          'label_number': tf.io.FixedLenFeature([], tf.int64),\n",
        "        }\n",
        "\n",
        "        parsed = tf.io.parse_single_example(\n",
        "            serialized=proto,\n",
        "            features=features\n",
        "        )\n",
        "\n",
        "        image, label = parsed[\"image\"], parsed[\"label_number\"]\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "        image = tf.image.resize(image, (image_size, image_size))\n",
        "    \n",
        "        return image, label\n",
        "    \n",
        "    tfrecord_files = tf.io.gfile.glob(tfrecord_path)\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
        "    dataset = dataset.map(parse_example)\n",
        "    if is_training:\n",
        "      dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True)\n",
        "      dataset = dataset.repeat()\n",
        "\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.map(lambda image, label: (preprocess_image(image), label))\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "   \n",
        "    return dataset\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=False\n",
        ") "
      ],
      "metadata": {
        "id": "3L1rAB3fRduM"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SpectralNormalization\n",
        "\n",
        "\n",
        "class SpectralNormalization(Wrapper):\n",
        "    \"\"\"\n",
        "    Attributes:\n",
        "       layer: tensorflow keras layers (with kernel attribute)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, **kwargs):\n",
        "        super(SpectralNormalization, self).__init__(layer, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build `Layer`\"\"\"\n",
        "\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "\n",
        "            if not hasattr(self.layer, 'kernel'):\n",
        "                raise ValueError(\n",
        "                    '`SpectralNormalization` must wrap a layer that'\n",
        "                    ' contains a `kernel` for weights')\n",
        "\n",
        "            self.w = self.layer.kernel\n",
        "            self.w_shape = self.w.shape.as_list()\n",
        "            self.u = self.add_weight(\n",
        "                shape=tuple([1, self.w_shape[-1]]),\n",
        "                initializer=k.initializers.TruncatedNormal(stddev=0.02),\n",
        "                name='sn_u',\n",
        "                trainable=False,\n",
        "                dtype=tf.float32)\n",
        "\n",
        "        super(SpectralNormalization, self).build()\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Call `Layer`\"\"\"\n",
        "        # Recompute weights for each forward pass\n",
        "        self._compute_weights()\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "\n",
        "    def _compute_weights(self):\n",
        "        \"\"\"Generate normalized weights.\n",
        "        This method will update the value of self.layer.kernel with the\n",
        "        normalized value, so that the layer is ready for call().\n",
        "        \"\"\"\n",
        "        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n",
        "        eps = 1e-12\n",
        "        _u = tf.identity(self.u)\n",
        "        \n",
        "        _v = tf.matmul(_u, tf.transpose(w_reshaped))\n",
        "        _v = _v / tf.maximum(tf.reduce_sum(_v**2)**0.5, eps)\n",
        "        _u = tf.matmul(_v, w_reshaped)\n",
        "        _u = _u / tf.maximum(tf.reduce_sum(_u**2)**0.5, eps)\n",
        "\n",
        "        self.u.assign(_u)\n",
        "        sigma = tf.matmul(tf.matmul(_v, w_reshaped), tf.transpose(_u))\n",
        "\n",
        "        self.layer.kernel = self.w / sigma\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tf.TensorShape(\n",
        "            self.layer.compute_output_shape(input_shape).as_list())"
      ],
      "metadata": {
        "id": "dMyNZbcj_dsD",
        "cellView": "form"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ConditionalBatchNormalization\n",
        "\n",
        "class ConditionalBatchNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(ConditionalBatchNormalization, self).__init__(**kwargs)\n",
        "    \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "   \n",
        "    self.linear_gamma = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_gamma'))\n",
        "    self.linear_beta = SpectralNormalization(tf.keras.layers.Dense(channels, \n",
        "\t\t\tkernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully,\n",
        "\t\t\tuse_bias = False,\n",
        "\t\t\tname = 'linear_beta'))\n",
        "    self.batchnorm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "  def call(self, x, c, training=False):\n",
        "    x = self.batchnorm(x, training=training)\n",
        "    gamma = self.linear_gamma(c, training=training)  \n",
        "    beta = self.linear_beta(c, training=training)\n",
        "\n",
        "    return x * gamma[:, None, None] + beta[:, None, None]  "
      ],
      "metadata": {
        "id": "d4RfhN_MT1Qv",
        "cellView": "form"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SelfAttention\n",
        "\n",
        "class SelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = int(input_shape[-1])\n",
        "\n",
        "        self.conv_theta =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_phi =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//8, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_g =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels//2, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.conv_attn =  SpectralNormalization(tf.keras.layers.Conv2D(padding='valid', kernel_size=1, filters=in_channels, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "        self.sigma = self.add_weight('sigma', shape=[], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        batch_size, h, w, in_channels = map(int, x.shape.as_list())\n",
        "        location_num = h*w\n",
        "        downsampled_num = location_num//4\n",
        "\n",
        "        theta = self.conv_theta(x, training=training)\n",
        "        theta = tf.reshape(theta, [batch_size, location_num, in_channels//8])\n",
        "\n",
        "        phi = self.conv_phi(x, training=training)\n",
        "        phi = tf.nn.max_pool(phi, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        phi = tf.reshape(phi, [batch_size, downsampled_num, in_channels//8])\n",
        "\n",
        "        attn = tf.matmul(theta, phi, transpose_b=True)\n",
        "        attn = tf.nn.softmax(attn)\n",
        "\n",
        "        g = self.conv_g(x, training=training)\n",
        "        g = tf.nn.max_pool(g, ksize=[2, 2], strides=2, padding='VALID')\n",
        "        g = tf.reshape(g, [batch_size, downsampled_num, in_channels//2])\n",
        "\n",
        "        attn_g = tf.matmul(attn, g)\n",
        "        attn_g = tf.reshape(attn_g, [batch_size, h, w, in_channels//2])\n",
        "        attn_g = self.conv_attn(attn_g, training=training)\n",
        "\n",
        "        return x + self.sigma * attn_g"
      ],
      "metadata": {
        "id": "MdSa_hc6UCm5",
        "cellView": "form"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DBlock\n",
        "\n",
        "class DBlock(Model):\n",
        "  def __init__(self, channels, downsample=True, preactivation=True):\n",
        "    super(DBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.hidden_channels = self.out_channels \n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.hidden_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.av_pool_1 = AveragePooling2D(padding='same')\n",
        "    self.av_pool_2 = AveragePooling2D(padding='same')\n",
        "    \n",
        "    self.downsample = downsample\n",
        "    self.preactivation = preactivation\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = True if (self.in_channels != self.out_channels) or self.downsample else False\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = tfa.layers.SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "\n",
        "  def shortcut(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "    else:\n",
        "      if self.downsample:\n",
        "        x = self.av_pool_1(x)\n",
        "      if self.learnable_sc:\n",
        "        x = self.conv_sc(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    if self.preactivation:\n",
        "      h = self.activation1(x)\n",
        "    else:\n",
        "      h = x    \n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.conv33_2(self.activation2(h), training=training)\n",
        "\n",
        "    if self.downsample:\n",
        "      h = self.av_pool_2(h)     \n",
        "        \n",
        "    return h + self.shortcut(x, training=training)           \n"
      ],
      "metadata": {
        "id": "qPc_lNVnTezv",
        "cellView": "form"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GBlock\n",
        "\n",
        "class GBlock(Model):\n",
        "  def __init__(self, channels):\n",
        "    super(GBlock, self).__init__()\n",
        "    self.out_channels = channels\n",
        "    self.bn1 = ConditionalBatchNormalization()\n",
        "    self.bn2 = ConditionalBatchNormalization()\n",
        "    self.up_sample_1 = UpSampling2D()\n",
        "    self.up_sample_2 = UpSampling2D()\n",
        "    self.activation1 = tf.keras.layers.ReLU()\n",
        "    self.activation2 = tf.keras.layers.ReLU()\n",
        "    self.conv33_1 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.conv33_2 = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.upsample = True\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    batch, height, width, channels = input_shape\n",
        "    self.in_channels = channels\n",
        "    self.learnable_sc = self.in_channels != self.out_channels\n",
        "\n",
        "    if self.learnable_sc:\n",
        "      self.conv_sc = SpectralNormalization(Conv2D(filters=self.out_channels, kernel_size=1, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "      \n",
        "  def call(self, x, label, training=False):\n",
        "    h = self.activation1(self.bn1(x, label, training=training))\n",
        "    if self.upsample:\n",
        "      h = self.up_sample_1(h)\n",
        "      x = self.up_sample_2(x)\n",
        "\n",
        "    h = self.conv33_1(h, training=training)\n",
        "    h = self.activation2(self.bn2(h, label, training=training))\n",
        "    h = self.conv33_2(h, training=training)\n",
        "\n",
        "    if self.learnable_sc:       \n",
        "      x = self.conv_sc(x, training=training)\n",
        "\n",
        "    return h + x"
      ],
      "metadata": {
        "id": "-Xi8EUT4TVtc",
        "cellView": "form"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generator\n",
        "\n",
        "class Generator(Model):\n",
        "  def __init__(self, channels, num_classes, embedding_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.linear = SpectralNormalization(Dense(4 * 4 * 16 * channels, use_bias=False, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully))\n",
        "    self.reshape = Reshape([4, 4, 16 * channels])\n",
        "\n",
        "    self.res_block_1 = GBlock(16 * channels)\n",
        "    self.res_block_2 = GBlock(16 * channels)\n",
        "    self.res_block_3 = GBlock(8 * channels)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_4 = GBlock(4 * channels)\n",
        "\n",
        "    self.embedding = Embedding(num_classes, embedding_size, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.bn = BatchNormalization()\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.conv = SpectralNormalization(Conv2D(filters=3, kernel_size=3, padding='same', kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer))\n",
        "    self.concat = tf.keras.layers.Concatenate();\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, z, label, training=False):    \n",
        "    z_split = tf.split(z, num_or_size_splits=5, axis=-1)\n",
        "    embed = self.embedding(label)\n",
        "    conds = [self.concat([z_i, embed]) for z_i in z_split[1:]]\n",
        "    x = self.linear(z_split[0], training=training)\n",
        "    x = self.reshape(x)\n",
        "    x = self.res_block_1(x, conds[0], training=training)\n",
        "    x = self.res_block_2(x, conds[1], training=training)\n",
        "    x = self.res_block_3(x, conds[2], training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_4(x, conds[3], training=training)\n",
        "    x = self.bn(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv(x, training=training)\n",
        "    return tf.nn.tanh(x)"
      ],
      "metadata": {
        "id": "wAcHyLVwUIBx"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator = Generator(64, num_classes=NUM_CLASSES, embedding_size=LATENT_DIM)"
      ],
      "metadata": {
        "id": "VPNrm_yZUIEW"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Discriminator\n",
        "\n",
        "class Discriminator(Model):\n",
        "  def __init__(self, channels, num_classes):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.res_block_1 = DBlock(1 * channels, downsample=True, preactivation=False)\n",
        "    self.res_block_2 = DBlock(2 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_3 = DBlock(4 * channels, downsample=True, preactivation=True)\n",
        "    self.res_block_4 = DBlock(8 * channels, downsample=True, preactivation=True)\n",
        "    self.attention = SelfAttention()\n",
        "    self.res_block_5 = DBlock(16 * channels, downsample=False, preactivation=True)\n",
        "    self.activation = tf.keras.layers.ReLU()\n",
        "    self.embedding = Embedding(num_classes, 16 * channels, embeddings_initializer=weight_initializer)\n",
        "\n",
        "    self.linear = SpectralNormalization(\n",
        "       Dense(1, kernel_initializer=weight_initializer, kernel_regularizer=weight_regularizer_fully)\n",
        "    )\n",
        "  \n",
        "  @tf.function\n",
        "  def call(self, x, label, training=False):\n",
        "    x = self.res_block_1(x, training=training)\n",
        "    x = self.res_block_2(x, training=training)\n",
        "    x = self.res_block_3(x, training=training)\n",
        "    x = self.res_block_4(x, training=training)\n",
        "    x = self.attention(x, training=training)\n",
        "    x = self.res_block_5(x, training=training)\n",
        "    x = self.activation(x)\n",
        "    x = tf.reduce_sum(x, axis=[1, 2])\n",
        "    out = self.linear(x, training=training)\n",
        "    embed = self.embedding(label)\n",
        "    out += tf.reduce_sum(x * embed, axis=-1, keepdims=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "17n0QCgeWgmr",
        "cellView": "form"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  discriminator = Discriminator(64, num_classes=NUM_CLASSES)"
      ],
      "metadata": {
        "id": "4DkA2GYMW08M"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "per_replica_batch_size = BATCH_SIZE // strategy.num_replicas_in_sync\n",
        "\n",
        "train_dataset = strategy.distribute_datasets_from_function(\n",
        "    lambda _: get_tfrecord_dataset(\n",
        "    batch_size=per_replica_batch_size,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    tfrecord_path=TFRECORD_PATH, \n",
        "    is_training=True\n",
        "))"
      ],
      "metadata": {
        "id": "ToBbMNEoXAGu"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_hinge_loss(logits_real: tf.Tensor, logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "  L_D = -tf.reduce_mean(tf.minimum(0., -1.0 + logits_real)) - tf.reduce_mean(tf.minimum(0., -1.0 - logits_fake))\n",
        "\n",
        "  return L_D    \n",
        "\n",
        "def generator_hinge_loss(logits_fake: tf.Tensor) -> tf.Tensor:\n",
        "    L_G = -tf.reduce_mean(logits_fake)\n",
        "    return L_G  "
      ],
      "metadata": {
        "id": "lSgabhufXH1S"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.0, beta_2=0.999,epsilon=1e-6,)\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(4e-4, beta_1=0.0, beta_2=0.999, epsilon=1e-6)"
      ],
      "metadata": {
        "id": "2yobBS03XJsS"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = tf.random.truncated_normal((100, LATENT_DIM), stddev=1)\n",
        "\n",
        "def sample_images(epoch):\n",
        "  rows = 10\n",
        "  cols = 10\n",
        "\n",
        "  noise = fixed_noise\n",
        "\n",
        "  labels = np.arange(0, 100)\n",
        "  gen_imgs = generator(noise, labels)\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.subplots_adjust(wspace=0.01, hspace=0)\n",
        "\n",
        "  fig.set_figheight(100)\n",
        "  fig.set_figwidth(100)\n",
        "  fig.set_tight_layout(True)\n",
        " \n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      axs[i,j].imshow(gen_imgs[j * 10 + i])\n",
        "  \n",
        "      axs[i,j].axis('off')\n",
        "  plt.savefig(SAMPLES_DIR + '/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "eBIiqqbOXLlW"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title train_step\n",
        "\n",
        "with strategy.scope():\n",
        "  d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "  g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(iterator):\n",
        "  \"\"\"The step function for one training step.\"\"\"\n",
        "\n",
        "  def step_fn(inputs):\n",
        "    \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "    images, labels = inputs\n",
        "    noise = tf.random.normal([per_replica_batch_size, LATENT_DIM])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, labels, training=True)\n",
        "      gen_predictions = discriminator(generated_images, labels, training=True)\n",
        "      real_predictions = discriminator(images, labels, training=True)\n",
        "      disc_loss = discriminator_hinge_loss(real_predictions, gen_predictions)\n",
        "      gen_loss = generator_hinge_loss(gen_predictions)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_weights)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_weights))\n",
        " \n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_weights)\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_weights)\n",
        "    )\n",
        "    \n",
        "    d_loss_metric.update_state(disc_loss)\n",
        "    g_loss_metric.update_state(gen_loss)\n",
        "    return disc_loss, gen_loss\n",
        "\n",
        "  disc_loss, gen_loss = strategy.run(step_fn, args=(next(iterator),))\n",
        "\n",
        "  disc_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, disc_loss, axis=None)\n",
        "  gen_loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, gen_loss, axis=None)\n",
        "  \n",
        "  return disc_loss, gen_loss"
      ],
      "metadata": {
        "id": "8PE9md58XNvq"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checkpoint\n",
        "\n",
        "with strategy.scope():\n",
        "  current_epoch = tf.Variable(0);\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    current_epoch=current_epoch\n",
        ")\n",
        "\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "latest_checkpoint = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
        "status = checkpoint.restore(latest_checkpoint, options=local_device_option)\n",
        "\n",
        "def save_checkpoint():\n",
        "  checkpoint_dir = CHECKPOINT_DIR\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)"
      ],
      "metadata": {
        "id": "JlPAqdghEYZ9"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  label = tf.constant([1])\n",
        "  noise = tf.random.truncated_normal([1, 120], stddev=0.5)\n",
        "  generated_image = generator(noise, label, training=False)\n",
        "  print(generated_image.shape)\n",
        "  plt.imshow(generated_image[0] * 0.5 + 0.5)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "shjyDN-zLfpG",
        "outputId": "4de72179-5f76-49a2-e506-8b8e6aede971"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 64, 64, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  decision = discriminator(generated_image, label)\n",
        "  print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQyAtYtnLn8B",
        "outputId": "1d11318f-42bf-4e51-a40f-6b9a4ab93f1c"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.0020431]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = DATASET_SIZE // BATCH_SIZE\n",
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(current_epoch.numpy(), EPOCHS):\n",
        "  current_epoch.assign(epoch);\n",
        "  start = time.time()\n",
        "  print('Epoch: {}/{}'.format(epoch + 1, EPOCHS))\n",
        "\n",
        "  pbar = tqdm(range(steps_per_epoch))\n",
        "  for step in pbar:\n",
        "    disc_loss, gen_loss = train_step(train_iterator)\n",
        "    pbar.set_postfix({'disc_loss': round(float(disc_loss), 4), 'gen_loss': round(float(gen_loss), 4)})\n",
        "    pbar.set_description(\"Current step %s\" % generator_optimizer.iterations.numpy())\n",
        "    \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    sample_images(epoch)\n",
        "    \n",
        "  if (epoch + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "    save_checkpoint()\n",
        "\n",
        "  print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky4ZH-23EiPG",
        "outputId": "e96a5b85-bd3a-40cd-84df-21d662edd49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/414 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"PartitionedCall_1:2\", shape=(4,), dtype=int64), values=Tensor(\"PartitionedCall_1:1\", shape=(4, 120), dtype=float32), dense_shape=Tensor(\"PartitionedCall_1:3\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"concat_1:0\", shape=(8,), dtype=int64), values=Tensor(\"concat:0\", shape=(8, 1024), dtype=float32), dense_shape=Tensor(\"PartitionedCall_2:59\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "Current step 414: 100%|██████████| 414/414 [06:23<00:00,  1.08it/s, disc_loss=1.35, gen_loss=1.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 1 is 383.9596040248871 sec\n",
            "Epoch: 2/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 828: 100%|██████████| 414/414 [00:36<00:00, 11.48it/s, disc_loss=0.847, gen_loss=0.218]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for epoch 2 is 36.083027362823486 sec\n",
            "Epoch: 3/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Current step 1057:  55%|█████▌    | 228/414 [00:20<00:16, 11.29it/s, disc_loss=0.418, gen_loss=1.27]"
          ]
        }
      ]
    }
  ]
}